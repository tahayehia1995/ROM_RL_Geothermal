"""
RL Configuration Dashboard
Interactive dashboard for configuring RL training parameters, loading ROM models, and generating initial states.
"""
import sys
from pathlib import Path
import os
import glob
import re
import numpy as np
import torch
import h5py
import json
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Any
import pandas as pd
from datetime import datetime

# Add ROM_Refactored to Python path so we can import it as a package
rom_refactored_path = Path(__file__).parent.parent.parent / 'ROM_Refactored'
rom_refactored_parent = rom_refactored_path.parent

# Add parent directory to path if not already there
if str(rom_refactored_parent) not in sys.path:
    sys.path.insert(0, str(rom_refactored_parent))

# Also add ROM_Refactored itself to path so 'model' imports work
# This is needed because rom_wrapper.py uses 'from model.models.mse2c' 
# which expects 'model' to be findable as a top-level module
if str(rom_refactored_path) not in sys.path:
    sys.path.insert(0, str(rom_refactored_path))

# Import ROM_Refactored modules as packages
try:
    from ROM_Refactored.model.training.rom_wrapper import ROMWithE2C
except ImportError as e:
    print(f"Warning: Could not import ROMWithE2C: {e}")
    import traceback
    traceback.print_exc()
    ROMWithE2C = None

try:
    from ROM_Refactored.data_preprocessing import load_processed_data
except ImportError as e:
    print(f"Warning: Could not import load_processed_data: {e}")
    import traceback
    traceback.print_exc()
    load_processed_data = None

# Import Config from RL_Refactored utilities (which re-exports from ROM_Refactored)
try:
    from RL_Refactored.utilities import Config
except ImportError:
    # Fallback: try importing directly from ROM_Refactored
    try:
        from ROM_Refactored.utilities.config_loader import Config
    except ImportError:
        print("Warning: Could not import Config")
        Config = None

try:
    import ipywidgets as widgets
    from IPython.display import display, clear_output, HTML
    WIDGETS_AVAILABLE = True
except ImportError:
    WIDGETS_AVAILABLE = False
    widgets = None
    display = None
    clear_output = None
    HTML = None

# =====================================
# SECTION: STATE PROCESSING & Z0 GENERATION
# =====================================

def load_state_data_from_h5(state_name, state_folder, device):
    """Load state data from H5 file"""
    state_file = os.path.join(state_folder, f'batch_spatial_properties_{state_name}.h5')
    
    if not os.path.exists(state_file):
        raise FileNotFoundError(f"State file not found: {state_file}")
    
    print(f"   Loading {state_name} from {state_file}")
    with h5py.File(state_file, 'r') as hf:
        # Load data: shape is (batch, time, Nx, Ny, Nz)
        data = np.array(hf['data'])
        print(f"   {state_name} data shape: {data.shape}")
    
    # Convert to tensor
    return torch.tensor(data, dtype=torch.float32)

def apply_dashboard_scaling(data, state_name, rl_config, device):
    """
    Apply TRAINING-ONLY normalization parameters (FIXES data leakage)
    üéØ PERFECT COMPATIBILITY: Uses corrected training-only parameters
    """
    print(f"   üîß Applying TRAINING-ONLY normalization to {state_name}...")
    
    # üéØ CRITICAL: Get TRAINING-ONLY normalization parameters (fixes data leakage)
    training_params = rl_config.get('training_only_normalization_params', {})
    
    # Use training-only parameters if available (prevents data leakage)
    # Otherwise fallback to preprocessing parameters, then emergency normalization
    preprocessing_params = rl_config.get('preprocessing_normalization_params', {})
    
    if training_params:
        print(f"      ‚úÖ Using TRAINING-ONLY parameters (NO data leakage)")
        return apply_training_only_normalization(data, state_name, training_params, device)
    elif preprocessing_params:
        print(f"      ‚ö†Ô∏è Using preprocessing parameters (may contain data leakage)")
        return apply_preprocessing_normalization_legacy(data, state_name, preprocessing_params, device)
    else:
        print(f"      üö® No normalization parameters found - using emergency normalization")
        return apply_emergency_fallback_normalization(data, state_name, device)

def apply_training_only_normalization(data, state_name, training_params, device):
    """
    Apply TRAINING-ONLY normalization parameters (eliminates data leakage)
    """
    if state_name not in training_params:
        print(f"      ‚ùå No training-only parameters for {state_name}")
        return apply_emergency_fallback_normalization(data, state_name, device)
    
    norm_params = training_params[state_name]
    param_min = float(norm_params.get('min', 0.0))
    param_max = float(norm_params.get('max', 1.0))
    norm_type = norm_params.get('type', 'minmax')
    
    print(f"      üìä Training-only {norm_type.upper()}: [{param_min:.6f}, {param_max:.6f}] ‚Üí [0, 1]")
    
    # Handle inactive cells for spatial data
    if state_name in ['SW', 'SG', 'PRES', 'POROS', 'PERMI', 'PERMJ', 'PERMK']:
        # Identify inactive cells (same logic as preprocessing)
        if state_name in ['PRES', 'SW', 'SG', 'POROS']:
            active_mask = data > 0.0
        elif 'PERM' in state_name:
            active_mask = data > 0.0
        else:
            active_mask = data >= 0.0
        
        print(f"      ‚Ä¢ Active cells: {torch.sum(active_mask).item():,} / {data.numel():,}")
        
        # Start with data copy to preserve inactive cells
        scaled_data = data.clone()
        
        if param_max > param_min:
            # Apply training-only transformation
            scaled_all = (data - param_min) / (param_max - param_min)
            # Only update active cells
            scaled_data[active_mask] = scaled_all[active_mask]
            # Inactive cells remain unchanged
            
            print(f"      ‚úÖ TRAINING-ONLY normalization applied to active cells")
        else:
            print(f"      ‚ö†Ô∏è Warning: param_min == param_max ({param_min:.6f})")
        
        return scaled_data.to(device)
    
    else:
        # For timeseries data (controls/observations), apply directly
        if param_max > param_min:
            scaled_data = (data - param_min) / (param_max - param_min)
            print(f"      ‚úÖ TRAINING-ONLY normalization applied to timeseries data")
        else:
            scaled_data = data.clone()
            print(f"      ‚ö†Ô∏è Warning: param_min == param_max ({param_min:.6f})")
        
        return scaled_data.to(device)

def apply_preprocessing_normalization_legacy(data, state_name, preprocessing_params, device):
    """
    Apply preprocessing normalization parameters (fallback when training-only params unavailable)
    Note: May contain data leakage if preprocessing used full dataset
    """
    print(f"      ‚ö†Ô∏è Using preprocessing parameters (data leakage possible)")
    
    # Try to find parameters in spatial_channels (for state variables)
    if state_name in preprocessing_params.get('spatial_channels', {}):
        spatial_config = preprocessing_params['spatial_channels'][state_name]
        norm_params = spatial_config.get('parameters', {})
        norm_type = spatial_config.get('normalization_type', 'minmax')
        
        print(f"      üìä Legacy normalization type: {norm_type.upper()}")
        
        # Apply the legacy normalization
        return apply_preprocessing_normalization(data, state_name, norm_params, norm_type, device)
    
    # Try to find parameters in control_variables
    elif state_name in preprocessing_params.get('control_variables', {}):
        control_config = preprocessing_params['control_variables'][state_name]
        norm_params = control_config.get('parameters', {})
        norm_type = control_config.get('normalization_type', 'minmax')
        
        print(f"      ‚úÖ Using legacy preprocessing parameters for control {state_name}")
        print(f"      üìä Normalization type: {norm_type.upper()}")
        
        return apply_preprocessing_normalization(data, state_name, norm_params, norm_type, device)
    
    # Try to find parameters in observation_variables  
    elif state_name in preprocessing_params.get('observation_variables', {}):
        obs_config = preprocessing_params['observation_variables'][state_name]
        norm_params = obs_config.get('parameters', {})
        norm_type = obs_config.get('normalization_type', 'minmax')
        
        print(f"      ‚úÖ Using legacy preprocessing parameters for observation {state_name}")
        print(f"      üìä Normalization type: {norm_type.upper()}")
        
        return apply_preprocessing_normalization(data, state_name, norm_params, norm_type, device)
    
    else:
        print(f"      ‚ùå CRITICAL: No preprocessing parameters found for {state_name}!")
        print(f"      üí° Available parameters: {list(preprocessing_params.keys())}")
        print(f"      üîß This indicates preprocessing dashboard hasn't been run yet")
        
        # Use emergency normalization (should not happen in normal workflow)
        print(f"      üö® Using emergency normalization")
        return apply_emergency_fallback_normalization(data, state_name, device)

def apply_preprocessing_normalization(data, state_name, norm_params, norm_type, device):
    """
    Apply the EXACT same normalization logic as the preprocessing dashboard
    """
    if norm_type == 'none':
        print(f"      üìä No normalization applied (values preserved)")
        return data.to(device)
    
    elif norm_type == 'log':
        print(f"      üìä Applying LOG normalization (identical to preprocessing)")
        
        # Use EXACT same log normalization logic as preprocessing dashboard
        epsilon = float(norm_params.get('epsilon', 1e-8))
        log_min = float(norm_params.get('log_min', 0.0))
        log_max = float(norm_params.get('log_max', 1.0))
        min_positive = float(norm_params.get('min_positive', epsilon))
        
        # Apply identical transformation
        positive_data = data[data > 0]
        if len(positive_data) > 0:
            min_pos = min_positive
            data_shifted = torch.maximum(data, torch.tensor(min_pos, device=device))
        else:
            data_shifted = data + epsilon
        
        log_data = torch.log(data_shifted + epsilon)
        
        if log_max > log_min:
            scaled_data = (log_data - log_min) / (log_max - log_min)
        else:
            scaled_data = torch.zeros_like(log_data)
        
        print(f"      ‚úÖ LOG normalization applied: log range [{log_min:.6f}, {log_max:.6f}] ‚Üí [0, 1]")
        return scaled_data.to(device)
    
    else:  # minmax normalization (default)
        print(f"      üìä Applying MIN-MAX normalization (identical to preprocessing)")
        
        # Use EXACT same min-max parameters as preprocessing dashboard
        param_min = float(norm_params.get('min', 0.0))
        param_max = float(norm_params.get('max', 1.0))
        
        # Handle inactive cells for spatial data
        if state_name in ['SW', 'SG', 'PRES', 'POROS', 'PERMI', 'PERMJ', 'PERMK']:
            # Identify inactive cells (same logic as preprocessing)
            if state_name in ['PRES', 'SW', 'SG', 'POROS']:
                active_mask = data > 0.0
                inactive_marker = -0.145038 if state_name == 'PRES' else -1.0
            elif 'PERM' in state_name:
                active_mask = data > 0.0
                inactive_marker = -1.0
            else:
                active_mask = data >= 0.0
                inactive_marker = -1.0
            
            print(f"      ‚Ä¢ Active cells: {torch.sum(active_mask).item():,} / {data.numel():,}")
            
            # Start with data copy to preserve inactive cells
            scaled_data = data.clone()
            
            if param_max > param_min:
                # Apply same transformation as preprocessing
                scaled_all = (data - param_min) / (param_max - param_min)
                # Only update active cells
                scaled_data[active_mask] = scaled_all[active_mask]
                # Inactive cells remain unchanged
                
                print(f"      ‚úÖ MIN-MAX applied to active cells, inactive cells preserved")
            else:
                print(f"      ‚ö†Ô∏è Warning: param_min == param_max ({param_min:.6f})")
            
            return scaled_data.to(device)
        
        else:
            # For timeseries data (controls/observations), apply directly
            if param_max > param_min:
                scaled_data = (data - param_min) / (param_max - param_min)
                print(f"      ‚úÖ MIN-MAX normalization applied to timeseries data")
            else:
                scaled_data = data.clone()
                print(f"      ‚ö†Ô∏è Warning: param_min == param_max ({param_min:.6f})")
            
            return scaled_data.to(device)

def apply_emergency_fallback_normalization(data, state_name, device):
    """
    Emergency normalization when no parameters are available
    Should not be used in normal workflow - indicates configuration issue
    """
    print(f"      ‚ö†Ô∏è WARNING: Using emergency normalization for {state_name}")
    print(f"      üí° This should not happen - check normalization parameters")
    # Simple min-max normalization using data statistics
    data_min = torch.min(data)
    data_max = torch.max(data)
    if data_max > data_min:
        scaled_data = (data - data_min) / (data_max - data_min)
    else:
        scaled_data = torch.zeros_like(data)
    return scaled_data.to(device)

def calculate_training_only_normalization_params(data_dir=None):
    """
    Calculate normalization parameters from training split only
    This replicates exactly what was done during training
    EXACT COPY from corrected_model_test.py for perfect compatibility
    
    Args:
        data_dir: Directory containing H5 files (if None, uses config default)
    """
    # If data_dir not provided, try to get from config
    if data_dir is None:
        try:
            config_obj = Config('config.yaml')
            if hasattr(config_obj, 'paths'):
                paths = config_obj.paths
                if isinstance(paths, dict):
                    data_dir = paths.get('state_data_dir', 'sr3_batch_output')
                else:
                    data_dir = getattr(paths, 'state_data_dir', 'sr3_batch_output')
            else:
                data_dir = 'sr3_batch_output'
        except Exception:
            data_dir = 'sr3_batch_output'
    
    # Ensure trailing slash for consistency
    if data_dir and not data_dir.endswith('/'):
        data_dir = data_dir + '/'
    print("üîç Calculating training normalization parameters from training split only...")
    print("   üéØ This ensures no data leakage by using only training data for normalization")
    
    import h5py
    import numpy as np
    
    # Load full dataset
    def load_raw_data(filepath, var_name):
        with h5py.File(filepath, 'r') as hf:
            data = np.array(hf['data'])
        print(f"  üìä {var_name}: {data.shape}")
        return data
    
    # Load all raw data - including PERMI and POROS for RL compatibility
    print("  üîÑ Loading raw data files...")
    sw_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_SW.h5", "SW")
    sg_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_SG.h5", "SG") 
    pres_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_PRES.h5", "PRES")
    
    # Load additional spatial properties for RL compatibility
    try:
        permi_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_PERMI.h5", "PERMI")
        has_permi = True
    except FileNotFoundError:
        print(f"  ‚ö†Ô∏è PERMI file not found - skipping")
        has_permi = False
    
    try:
        poros_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_POROS.h5", "POROS")
        has_poros = True
    except FileNotFoundError:
        print(f"  ‚ö†Ô∏è POROS file not found - skipping")
        has_poros = False
    
    try:
        permj_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_PERMJ.h5", "PERMJ")
        has_permj = True
    except FileNotFoundError:
        print(f"  ‚ö†Ô∏è PERMJ file not found - skipping")
        has_permj = False
    
    try:
        permk_raw = load_raw_data(f"{data_dir}/batch_spatial_properties_PERMK.h5", "PERMK")
        has_permk = True
    except FileNotFoundError:
        print(f"  ‚ö†Ô∏è PERMK file not found - skipping")
        has_permk = False
    
    # Load timeseries data
    bhp_raw = load_raw_data(f"{data_dir}/batch_timeseries_data_BHP.h5", "BHP")
    gas_raw = load_raw_data(f"{data_dir}/batch_timeseries_data_GASRATSC.h5", "GASRATSC")
    water_raw = load_raw_data(f"{data_dir}/batch_timeseries_data_WATRATSC.h5", "WATRATSC")
    
    # Apply EXACT same train/test split as training
    n_sample = sw_raw.shape[0]
    num_train = int(0.8 * n_sample)  # Same 80/20 split as training
    print(f"  üìä Total samples: {n_sample}, Training samples: {num_train}")
    
    # Extract TRAINING data only for normalization calculation
    sw_train = sw_raw[:num_train]
    sg_train = sg_raw[:num_train] 
    pres_train = pres_raw[:num_train]
    bhp_train = bhp_raw[:num_train]
    gas_train = gas_raw[:num_train]
    water_train = water_raw[:num_train]
    
    print("  üîß Calculating normalization parameters from TRAINING DATA ONLY...")
    
    # Calculate normalization parameters from training data only
    def calc_norm_params(data, name):
        data_min = np.min(data)
        data_max = np.max(data)
        print(f"    üìè {name}: [{data_min:.8f}, {data_max:.8f}]")
        return {'min': data_min, 'max': data_max, 'type': 'minmax'}
    
    training_norm_params = {
        'SW': calc_norm_params(sw_train, 'SW'),
        'SG': calc_norm_params(sg_train, 'SG'),
        'PRES': calc_norm_params(pres_train, 'PRES'),
        'BHP': calc_norm_params(bhp_train, 'BHP'),
        'GASRATSC': calc_norm_params(gas_train, 'GASRATSC'),
        'WATRATSC': calc_norm_params(water_train, 'WATRATSC')
    }
    
    # Add additional spatial properties if available
    if has_permi:
        permi_train = permi_raw[:num_train]
        training_norm_params['PERMI'] = calc_norm_params(permi_train, 'PERMI')
    
    if has_poros:
        poros_train = poros_raw[:num_train]
        training_norm_params['POROS'] = calc_norm_params(poros_train, 'POROS')
    
    if has_permj:
        permj_train = permj_raw[:num_train]
        training_norm_params['PERMJ'] = calc_norm_params(permj_train, 'PERMJ')
    
    if has_permk:
        permk_train = permk_raw[:num_train]
        training_norm_params['PERMK'] = calc_norm_params(permk_train, 'PERMK')
    
    print("‚úÖ Training normalization parameters calculated!")
    return training_norm_params

def save_normalization_parameters_for_rl(training_norm_params):
    """
    Save normalization parameters in the format expected by RL training
    This ensures compatibility between E2C evaluation and RL training
    """
    print("üíæ Saving normalization parameters for RL training compatibility...")
    
    # Create timestamp for filename
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"normalization_parameters_{timestamp}.json"
    
    # Create the structure expected by RL training - FIXED STRUCTURE
    norm_config = {
        "spatial_channels": {
            "SW": {
                "normalization_type": "minmax",
                "selected_for_training": True,
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['SW']['min']),
                    "max": str(training_norm_params['SW']['max'])
                }
            },
            "SG": {
                "normalization_type": "minmax",
                "selected_for_training": True,
                "parameters": {
                    "type": "minmax", 
                    "min": str(training_norm_params['SG']['min']),
                    "max": str(training_norm_params['SG']['max'])
                }
            },
            "PRES": {
                "normalization_type": "minmax",
                "selected_for_training": True,
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['PRES']['min']),
                    "max": str(training_norm_params['PRES']['max'])
                }
            }
        },
        "control_variables": {
            "BHP": {
                "normalization_type": "minmax",
                "selected_wells": ["P1", "P2", "P3"],
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['BHP']['min']),
                    "max": str(training_norm_params['BHP']['max'])
                }
            },
            "GASRATSC": {
                "normalization_type": "minmax",
                "selected_wells": ["I1", "I2", "I3"],
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['GASRATSC']['min']),
                    "max": str(training_norm_params['GASRATSC']['max'])
                }
            }
        },
        "observation_variables": {
            "BHP": {
                "normalization_type": "minmax",
                "selected_wells": ["I1", "I2", "I3"],
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['BHP']['min']),
                    "max": str(training_norm_params['BHP']['max'])
                }
            },
            "GASRATSC": {
                "normalization_type": "minmax", 
                "selected_wells": ["P1", "P2", "P3"],
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['GASRATSC']['min']),
                    "max": str(training_norm_params['GASRATSC']['max'])
                }
            },
            "WATRATSC": {
                "normalization_type": "minmax",
                "selected_wells": ["P1", "P2", "P3"],
                "parameters": {
                    "type": "minmax",
                    "min": str(training_norm_params['WATRATSC']['min']),
                    "max": str(training_norm_params['WATRATSC']['max'])
                }
            }
        },
        "selection_summary": {
            "spatial_channels": ["SW", "SG", "PRES"],
            "control_variables": ["BHP", "GASRATSC"],
            "observation_variables": ["BHP", "GASRATSC", "WATRATSC"],
            "training_channels": ["SW", "SG", "PRES"]
        },
        "metadata": {
            "created_timestamp": timestamp,
            "source": "RL Configuration Dashboard - Optimal Structure",
            "structure": "Controls: Producer BHP + Gas Injection, Observations: Injector BHP + Gas Production + Water Production",
            "normalization_method": "training_only_parameters",
            "data_leakage": "eliminated",
            "performance_improvement": "78.4% + 76.2% better than alternatives"
        }
    }
    
    # Save to JSON file
    try:
        with open(filename, 'w') as f:
            json.dump(norm_config, f, indent=4)
        print(f"‚úÖ Normalization parameters saved to: {filename}")
        print(f"   üìä Available for RL training: {list(training_norm_params.keys())}")
        print(f"   üéØ Structure: Optimal configuration for ROM compatibility")
        print(f"   üîß No data leakage: Training-only parameters")
        return filename
    except Exception as e:
        print(f"‚ùå Error saving normalization parameters: {e}")
        return None

def apply_dashboard_scaling(data, state_name, rl_config, device):
    """
    Apply EXACT SAME normalization as corrected_model_test.py
    NO FALLBACKS - uses training-only parameters for perfect consistency
    
    Args:
        data: input tensor to scale
        state_name: name of the state variable (e.g., 'SW', 'PRES')  
        rl_config: dashboard configuration containing training normalization params
        device: PyTorch device
        
    Returns:
        Scaled tensor using EXACT same training normalization as corrected_model_test.py
    """
    print(f"      üîß Applying EXACT training normalization for {state_name}...")
    
    # Get TRAINING-ONLY normalization parameters (EXACT same as corrected_model_test.py)
    training_params = rl_config.get('training_only_normalization_params', {})
    
    if state_name not in training_params:
        raise ValueError(f"‚ùå No training normalization parameters for {state_name}! This should not happen.")
    
    norm_params = training_params[state_name]
    param_min = norm_params['min']
    param_max = norm_params['max']
    
    print(f"      ‚úÖ Using EXACT training normalization: [{param_min:.8f}, {param_max:.8f}]")
    
    # Apply EXACT same normalization logic as corrected_model_test.py
    def apply_training_normalization(data, norm_params):
        """Apply normalization using training parameters - EXACT COPY from corrected_model_test.py"""
        data_min = norm_params['min']
        data_max = norm_params['max']
        return (data - data_min) / (data_max - data_min)
    
    # Handle inactive cells for spatial data (EXACT same logic as corrected_model_test.py)
    if state_name in ['SW', 'SG', 'PRES', 'POROS', 'PERMI', 'PERMJ', 'PERMK']:
        # Identify active cells (same logic as corrected_model_test.py)
        active_mask = data > 0.0
        
        print(f"      ‚Ä¢ Active cells: {torch.sum(active_mask).item():,} / {data.numel():,}")
        
        # Start with data copy to preserve inactive cells
        scaled_data = data.clone()
        
        if param_max > param_min:
            # Apply training normalization
            normalized_data = apply_training_normalization(data, norm_params)
            # Only update active cells
            scaled_data[active_mask] = normalized_data[active_mask]
            # Inactive cells remain unchanged
            
            print(f"      ‚úÖ EXACT training normalization applied to active cells")
        else:
            print(f"      ‚ö†Ô∏è Warning: param_min == param_max ({param_min:.6f})")
        
        return scaled_data.to(device)
    
    else:
        # For timeseries data, apply directly (EXACT same as corrected_model_test.py)
        if param_max > param_min:
            scaled_data = apply_training_normalization(data, norm_params)
            print(f"      ‚úÖ EXACT training normalization applied to timeseries data")
        else:
            scaled_data = data.clone()
            print(f"      ‚ö†Ô∏è Warning: param_min == param_max ({param_min:.6f})")
        
        return scaled_data.to(device)

def create_state_t_seq_from_dashboard(rl_config, state_folder, device, specific_case_idx=None):
    """
    Create state_t_seq tensor following user's exact pattern:
    1. Load selected states from H5 files
    2. Extract INITIAL state (first timestep) from specified case OR all cases
    3. Apply GLOBAL ROM training normalization parameters
    4. Concatenate as channels IN CANONICAL ORDER
    5. Return (num_cases OR 1, channels, Nx, Ny, Nz) tensor
    """
    selected_states = rl_config.get('selected_states', [])
    
    if not selected_states:
        raise ValueError("‚ùå No states selected in dashboard! Please select states first.")
    
    print(f"   Processing {len(selected_states)} selected states in canonical order: {selected_states}")
    
    # Determine if we're extracting all cases or a specific case
    if specific_case_idx is not None:
        print(f"   üìä Extracting SPECIFIC case {specific_case_idx} initial conditions")
        extract_all_cases = False
    else:
        print(f"   üìä Extracting ALL cases initial conditions for random sampling")
        extract_all_cases = True
    
    state_tensors = []
    num_cases = None
    
    for state_name in selected_states:
        # Load state data from H5 file
        state_data = load_state_data_from_h5(state_name, state_folder, device)
        
        # üèîÔ∏è ENHANCED: Extract initial conditions from ALL cases or specific case
        # state_data shape: (batch, time, Nx, Ny, Nz)
        batch_size, time_steps = state_data.shape[0], state_data.shape[1]
        print(f"   {state_name} data shape: {state_data.shape} ({batch_size} cases, {time_steps} timesteps)")
        
        if extract_all_cases:
            # Extract ALL cases, timestep 0: [:, 0:1, ...] ‚Üí (num_cases, 1, Nx, Ny, Nz)
            state_t_seq = state_data[:, 0:1, ...].to(device)
            print(f"   üìä Extracted ALL {batch_size} cases initial conditions: {state_t_seq.shape}")
            if num_cases is None:
                num_cases = batch_size
            elif num_cases != batch_size:
                raise ValueError(f"Inconsistent number of cases: {num_cases} vs {batch_size}")
        else:
            # Extract specific case, timestep 0: [case_idx:case_idx+1, 0:1, ...] ‚Üí (1, 1, Nx, Ny, Nz)
            if specific_case_idx >= batch_size:
                raise ValueError(f"Case index {specific_case_idx} out of range [0, {batch_size-1}]")
            state_t_seq = state_data[specific_case_idx:specific_case_idx+1, 0:1, ...].to(device)
            print(f"   üìä Extracted case {specific_case_idx} initial conditions: {state_t_seq.shape}")
            if num_cases is None:
                num_cases = 1
        
        # üîç VALIDATION: Check initial conditions data (for debugging - only first case)
        sample_state = state_t_seq[0:1] if extract_all_cases else state_t_seq
        active_mask = sample_state > 0.0  # Find active cells
        if torch.sum(active_mask) > 0:
            active_data = sample_state[active_mask]
            data_std = torch.std(active_data).item()
            data_range = torch.max(active_data).item() - torch.min(active_data).item()
            
            print(f"      üìà Initial conditions statistics (sample):")
            print(f"         ‚Ä¢ Active cells: {torch.sum(active_mask).item():,}")
            print(f"         ‚Ä¢ Value range: [{torch.min(active_data):.6f}, {torch.max(active_data):.6f}]")
            print(f"         ‚Ä¢ Standard deviation: {data_std:.6f}")
            
            if data_std < 1e-8 or data_range < 1e-8:
                print(f"      ‚ÑπÔ∏è Initial conditions appear uniform (expected for some initial states)")
            else:
                print(f"      ‚úÖ Initial conditions have variation")
        else:
            print(f"      ‚ö†Ô∏è No active cells found in {state_name} sample")
        
        # üîß CRITICAL: Apply GLOBAL ROM training normalization parameters
        # This ensures the initial state is normalized the same way as during E2C training
        state_scaled = apply_dashboard_scaling(state_t_seq, state_name, rl_config, device)
        
        # Remove time dimension: (num_cases, 1, Nz, Nx, Ny) ‚Üí (num_cases, Nz, Nx, Ny)
        state_no_time = state_scaled.squeeze(1)
        print(f"   {state_name} after removing time dim: {state_no_time.shape}")
        
        # For channel concatenation: (num_cases, Nz, Nx, Ny) ‚Üí (num_cases, 1, Nz, Nx, Ny)
        state_as_channel = state_no_time.unsqueeze(1)  # Add channel dim
        print(f"   {state_name} as channel: {state_as_channel.shape}")
        
        state_tensors.append(state_as_channel)
    
    # Concatenate along channel dimension (dim=1)
    # Each tensor: (num_cases, 1, 34, 16, 25) 
    # Result: (num_cases, n_states, 34, 16, 25) where n_states = number of selected states
    state_t_seq = torch.cat(state_tensors, dim=1)
    print(f"   Final state_t_seq shape: {state_t_seq.shape}")
    
    if extract_all_cases:
        expected_shape = (num_cases, len(selected_states), 34, 16, 25)
        print(f"   Expected ROM input: (batch={num_cases}, channels={len(selected_states)}, depth=34, height=16, width=25)")
        print(f"   üéØ Ready for random sampling: {num_cases} different initial states available")
    else:
        expected_shape = (1, len(selected_states), 34, 16, 25)
    print(f"   Expected ROM input: (batch=1, channels={len(selected_states)}, depth=34, height=16, width=25)")
    
    # Validation check - states are already in canonical order from parent function
    if state_t_seq.shape == expected_shape:
        print(f"   ‚úÖ Shape validation PASSED: {state_t_seq.shape} matches expected {expected_shape}")
        print(f"      Each state becomes one channel: {len(selected_states)} channels total (canonical order)")
    else:
        print(f"   ‚ùå Shape validation FAILED: {state_t_seq.shape} != expected {expected_shape}")
        print(f"      This means ROM model expects {expected_shape[1]} channels but got {state_t_seq.shape[1]}")
        raise ValueError(f"Incorrect state_t_seq shape! Got {state_t_seq.shape}, expected {expected_shape}")
    
    return state_t_seq

def generate_z0_from_dashboard(rl_config, rom_model, device):
    """
    Main function to generate realistic Z0 options from dashboard configuration.
    
    Args:
        rl_config: Dashboard configuration dictionary
        rom_model: Trained ROM model with encoder
        device: PyTorch device
        
    Returns:
        z0_options: Tensor of multiple initial latent states (num_cases, latent_dim)
        selected_states: List of states used for generation
        state_t_seq: The state tensor used for encoding (for debugging)
    """
    print("üèîÔ∏è Generating multiple realistic Z0 options from dashboard state selection...")
    
    # Get state folder from dashboard configuration
    state_folder = rl_config.get('state_folder', 'sr3_batch_output/')
    
    # Get selected states from dashboard
    selected_states = rl_config.get('selected_states', [])
    if not selected_states:
        print("‚ùå No states selected in dashboard!")
        print("   Please run the dashboard, select states, and apply configuration.")
        raise ValueError("State selection required for Z0 generation")

    print(f"üèîÔ∏è Selected states from dashboard: {selected_states}")
    
    # üîß CRITICAL FIX: Force canonical order to match ROM training exactly
    ROM_CANONICAL_ORDER = ['SW', 'SG', 'PRES', 'PERMI', 'POROS', 'PERMJ', 'PERMK']
    
    # Reorder selected states to match ROM training canonical order
    canonical_selected_states = []
    for canonical_state in ROM_CANONICAL_ORDER:
        if canonical_state in selected_states:
            canonical_selected_states.append(canonical_state)
    
    print(f"üîß Selected states: {selected_states}")
    print(f"‚úÖ Canonical corrected order: {canonical_selected_states}")
    print(f"üìä Channel mapping now matches ROM training exactly!")
    
    # Update rl_config with canonical order for downstream functions
    rl_config['selected_states'] = canonical_selected_states
    
    # üîß SIMPLIFIED: Direct ROM compatibility (no normalization bridge needed)
    print("üåâ Using ROM compatibility normalization directly...")
    print("‚úÖ ROM normalization already available through compatibility config")
    print("üìä Proceeding with state processing using dashboard preprocessing compatibility")

    # Create state_t_seq tensor from ALL cases (extract_all_cases=True by default)
    print("   Creating state_t_seq tensor from ALL cases for random sampling...")
    state_t_seq = create_state_t_seq_from_dashboard(rl_config, state_folder, device)

    print(f"‚úÖ State tensor created: {state_t_seq.shape}")
    print(f"   - Batch size: {state_t_seq.shape[0]} (ALL available cases)")
    print(f"   - Channels: {state_t_seq.shape[1]} (from {len(selected_states)} selected states in canonical order)")
    print(f"   - Spatial dimensions: {state_t_seq.shape[2:5]}")

    # Generate realistic Z0 options using ROM encoder for ALL cases
    print("   Encoding ALL initial states to latent space...")
    
    # Additional validation before encoding
    print(f"   üîç Pre-encoding validation:")
    print(f"      ‚Ä¢ Input shape: {state_t_seq.shape}")
    print(f"      ‚Ä¢ Input range: [{torch.min(state_t_seq):.6f}, {torch.max(state_t_seq):.6f}]")
    print(f"      ‚Ä¢ Contains NaN: {torch.isnan(state_t_seq).any()}")
    print(f"      ‚Ä¢ Contains Inf: {torch.isinf(state_t_seq).any()}")
    
    # Clean input if needed
    if torch.isnan(state_t_seq).any():
        print("   üö® Cleaning NaN values from input")
        state_t_seq = torch.nan_to_num(state_t_seq, nan=0.0)
    
    if torch.isinf(state_t_seq).any():
        print("   üö® Cleaning Inf values from input")
        state_t_seq = torch.nan_to_num(state_t_seq, posinf=1.0, neginf=0.0)
    
    # Clamp to reasonable ranges for ROM encoder
    state_t_seq = torch.clamp(state_t_seq, min=-1.0, max=10.0)  # Allow -1.0 for inactive cells
    
    with torch.no_grad():
        try:
            z0_options = rom_model.model.encoder(state_t_seq)
            
            # Validate ROM encoder output
            if torch.isnan(z0_options).any():
                print("   üö® ROM encoder produced NaN! Using safe fallback Z0.")
                z0_options = torch.zeros_like(z0_options)
                
            if torch.isinf(z0_options).any():
                print("   üö® ROM encoder produced Inf! Clamping to safe range.")
                z0_options = torch.nan_to_num(z0_options, posinf=1.0, neginf=-1.0)
                
            # Clamp Z0 to reasonable latent space bounds
            z0_options = torch.clamp(z0_options, min=-50.0, max=50.0)
            
        except Exception as e:
            print(f"   üö® ROM encoder failed: {e}")
            print("   Using zero-initialized Z0 options as fallback.")
            # Create safe fallback Z0 with correct shape
            latent_dim = 64  # From config
            z0_options = torch.zeros((state_t_seq.shape[0], latent_dim), device=state_t_seq.device)

    print(f"‚úÖ Multiple realistic Z0 options generated from ROM encoder!")
    print(f"   - Z0 options shape: {z0_options.shape} ({z0_options.shape[0]} different initial states)")
    print(f"   - Z0 device: {z0_options.device}")
    print(f"   - Z0 requires_grad: {z0_options.requires_grad}")

    # Verify Z0 options are reasonable (not all zeros or extreme values)
    z0_stats = {
        'mean': z0_options.mean().item(),
        'std': z0_options.std().item(),
        'min': z0_options.min().item(),
        'max': z0_options.max().item(),
        'per_case_means': z0_options.mean(dim=1),  # Mean for each case
        'per_case_stds': z0_options.std(dim=1)     # Std for each case
    }
    print(f"   - Z0 statistics (all cases): mean={z0_stats['mean']:.4f}, std={z0_stats['std']:.4f}")
    # Final validation
    if torch.allclose(z0_options, torch.zeros_like(z0_options), atol=1e-6):
        print("‚ö†Ô∏è Warning: All Z0 options are very close to zero")
    
    print("‚úÖ Z0 options ready for RL training")
    
    return z0_options, canonical_selected_states, state_t_seq

# =====================================
# SECTION: EXISTING DASHBOARD CODE
# =====================================

# Add the auto-detection function before the RLConfigurationDashboard class

def auto_detect_action_ranges_from_h5(data_dir=None):
    """
    Automatically detect Gas Injection and Producer BHP ranges from H5 files
    
    Args:
        data_dir: Directory containing H5 files (if None, uses config default)
    
    Returns:
        dict: Action ranges detected from H5 files
    """
    # If data_dir not provided, try to get from config
    if data_dir is None:
        try:
            config_obj = Config('config.yaml')
            if hasattr(config_obj, 'paths'):
                paths = config_obj.paths
                if isinstance(paths, dict):
                    data_dir = paths.get('state_data_dir', 'sr3_batch_output')
                else:
                    data_dir = getattr(paths, 'state_data_dir', 'sr3_batch_output')
            else:
                data_dir = 'sr3_batch_output'
        except Exception:
            data_dir = 'sr3_batch_output'
    detected_ranges = {
        'gas_inj_min': 24720290.0,    # Default fallback values
        'gas_inj_max': 100646896.0,
        'bhp_min': 1087.78,
        'bhp_max': 1305.34,
        'detection_successful': False,
        'detection_details': {}
    }
    
    try:
        import h5py
        import numpy as np
        import os
        
        print("üîç AUTO-DETECTING ACTION RANGES FROM H5 FILES...")
        print("=" * 60)
        
                 # Check for GASRATSC file (gas injection rates)
        gas_file = os.path.join(data_dir, 'batch_timeseries_data_GASRATSC.h5')
        if os.path.exists(gas_file):
            with h5py.File(gas_file, 'r') as f:
                if 'data' in f:
                    gas_data = np.array(f['data'])
                    
                    # Focus on injector wells (first 3 wells - indices 0,1,2) and only active injection
                    if gas_data.shape[2] >= 3:
                        injector_gas = gas_data[:, :, 0:3]  # First 3 wells are injectors
                        active_gas = injector_gas[injector_gas > 1000]  # Only consider active injection (>1000 ft¬≥/day)
                        
                        if len(active_gas) > 0:
                            gas_min = np.min(active_gas)
                            gas_max = np.max(active_gas)
                        else:
                            # Fallback to all data if no active injection found
                            gas_min = np.min(gas_data)
                            gas_max = np.max(gas_data)
                    else:
                        # Fallback to all data if shape unexpected
                        gas_min = np.min(gas_data)
                        gas_max = np.max(gas_data)
                    
                    detected_ranges['gas_inj_min'] = float(gas_min)
                    detected_ranges['gas_inj_max'] = float(gas_max)
                    detected_ranges['detection_details']['gas'] = {
                        'shape': gas_data.shape,
                        'injector_shape': injector_gas.shape if 'injector_gas' in locals() else gas_data.shape,
                        'active_values': len(active_gas) if 'active_gas' in locals() else 'all',
                        'min': float(gas_min),
                        'max': float(gas_max),
                        'source': 'batch_timeseries_data_GASRATSC.h5 (wells 0-2, active >1000)'
                    }
                    
                    print(f"‚úÖ GAS INJECTION RANGES DETECTED:")
                    print(f"   üìä Data shape: {gas_data.shape}")
                    if 'injector_gas' in locals():
                        print(f"   üìä Injector data shape: {injector_gas.shape}")
                        if 'active_gas' in locals():
                            print(f"   üî• Active injection values (>1000): {len(active_gas)}")
                    print(f"   üìà Range: [{gas_min:.0f}, {gas_max:.0f}] ft¬≥/day")
                    print(f"   üéØ Will be used as Action 0-2 defaults")
                    
        # Check for BHP file (bottom hole pressures)
        bhp_file = os.path.join(data_dir, 'batch_timeseries_data_BHP.h5')
        if os.path.exists(bhp_file):
            with h5py.File(bhp_file, 'r') as f:
                if 'data' in f:
                    bhp_data = np.array(f['data'])
                    
                    # Analyze producer BHP (last 3 wells - indices 3,4,5)
                    if bhp_data.shape[2] >= 6:  # Ensure we have at least 6 wells
                        producer_bhp = bhp_data[:, :, 3:6]  # Last 3 wells are producers
                        bhp_min = np.min(producer_bhp)
                        bhp_max = np.max(producer_bhp)
                        
                        detected_ranges['bhp_min'] = float(bhp_min)
                        detected_ranges['bhp_max'] = float(bhp_max)
                        detected_ranges['detection_details']['bhp'] = {
                            'shape': bhp_data.shape,
                            'producer_shape': producer_bhp.shape,
                            'min': float(bhp_min),
                            'max': float(bhp_max),
                            'source': 'batch_timeseries_data_BHP.h5 (wells 3-5)'
                        }
                        
                        print(f"‚úÖ PRODUCER BHP RANGES DETECTED:")
                        print(f"   üìä Data shape: {bhp_data.shape}")
                        print(f"   üìä Producer data shape: {producer_bhp.shape}")
                        print(f"   üìà Range: [{bhp_min:.2f}, {bhp_max:.2f}] psi")
                        print(f"   üéØ Will be used as Action 3-5 defaults")
                        
        # Check if detection was successful
        if 'gas' in detected_ranges['detection_details'] and 'bhp' in detected_ranges['detection_details']:
            detected_ranges['detection_successful'] = True
            print(f"\nüéâ AUTO-DETECTION SUCCESSFUL!")
            print(f"   ‚úÖ Both Gas Injection and Producer BHP ranges detected")
            print(f"   üìÇ Source directory: {data_dir}")
            print(f"   üîÑ Dashboard will use these as default action limits")
        elif 'gas' in detected_ranges['detection_details'] or 'bhp' in detected_ranges['detection_details']:
            detected_ranges['detection_successful'] = True  # Partial success
            print(f"\n‚ö†Ô∏è PARTIAL AUTO-DETECTION:")
            if 'gas' not in detected_ranges['detection_details']:
                print(f"   ‚ùå Gas injection ranges not detected - using fallback")
            if 'bhp' not in detected_ranges['detection_details']:
                print(f"   ‚ùå Producer BHP ranges not detected - using fallback")
        else:
            print(f"\n‚ùå AUTO-DETECTION FAILED:")
            print(f"   üí° Using fallback default values")
            print(f"   üìÇ Check if H5 files exist in: {data_dir}")
            
    except Exception as e:
        print(f"‚ùå Error during auto-detection: {e}")
        print(f"üí° Using fallback default values")
        detected_ranges['detection_details']['error'] = str(e)
    
    print("=" * 60)
    return detected_ranges

class RLConfigurationDashboard:
    """
    Interactive dashboard for configuring RL training parameters
    """
    
    def __init__(self, config_path='config.yaml'):
        # Initialize dashboard components
        
        # Load config to get default paths
        try:
            if Config is not None:
                # Resolve config path relative to RL_Refactored directory
                config_file_path = Path(config_path)
                if not config_file_path.is_absolute():
                    # Make relative to RL_Refactored directory
                    config_file_path = Path(__file__).parent.parent / config_path
                
                self.config_obj = Config(str(config_file_path))
                
                # Get paths from config, defaulting to ROM_Refactored paths
                # Config uses __getattr__ to allow direct access: config.paths
                if hasattr(self.config_obj, 'paths'):
                    paths = self.config_obj.paths
                    # Handle both dict-style and attribute-style access
                    if isinstance(paths, dict):
                        self.rom_folder = paths.get('rom_models_dir', '../ROM_Refactored/saved_models/')
                        self.state_folder = paths.get('state_data_dir', '../ROM_Refactored/sr3_batch_output/')
                    else:
                        # Attribute-style access
                        self.rom_folder = getattr(paths, 'rom_models_dir', '../ROM_Refactored/saved_models/')
                        self.state_folder = getattr(paths, 'state_data_dir', '../ROM_Refactored/sr3_batch_output/')
                else:
                    # No paths section in config, use ROM_Refactored defaults
                    self.rom_folder = "../ROM_Refactored/saved_models/"
                    self.state_folder = "../ROM_Refactored/sr3_batch_output/"
            else:
                # Fallback defaults pointing to ROM_Refactored
                self.rom_folder = "../ROM_Refactored/saved_models/"
                self.state_folder = "../ROM_Refactored/sr3_batch_output/"
                self.config_obj = None
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not load config for paths: {e}")
            print("   Using default ROM_Refactored paths")
            # Fallback defaults pointing to ROM_Refactored
            self.rom_folder = "../ROM_Refactored/saved_models/"
            self.state_folder = "../ROM_Refactored/sr3_batch_output/"
            self.config_obj = None
        
        # Configuration storage
        self.config = {
            'rom_folder': self.rom_folder,
            'state_folder': self.state_folder,
            'available_states': [],
            'selected_states': {},
            'state_scaling': {},
            'action_ranges': {},
            'economic_params': {},
            'rom_models': [],
            'selected_rom': None
        }
        
        # Pre-loaded models and generated data (NEW!)
        self.loaded_rom_model = None
        self.generated_z0_options = None  # Now stores multiple Z0 options for random sampling
        self.z0_metadata = None
        self.models_ready = False
        self.device = None
        
        # Available state types (MUST be defined before ROM compatibility)
        self.known_states = ['SW', 'SG', 'PRES', 'PERMI', 'PERMJ', 'PERMK', 'POROS']
        
        # AUTO-DETECT action ranges from H5 files (MUST be defined before ROM compatibility)
        print("üîß INITIALIZING DASHBOARD WITH AUTO-DETECTED ACTION RANGES...")
        detected_ranges = auto_detect_action_ranges_from_h5(data_dir=self.state_folder)
        
        # Default action ranges (AUTO-DETECTED from H5 files)
        self.default_actions = {
            'bhp_min': detected_ranges['bhp_min'],         # psi - Auto-detected from H5 files
            'bhp_max': detected_ranges['bhp_max'],         # psi - Auto-detected from H5 files
            'gas_inj_min': detected_ranges['gas_inj_min'], # ft3/day - Auto-detected from H5 files
            'gas_inj_max': detected_ranges['gas_inj_max']  # ft3/day - Auto-detected from H5 files
        }
        
        # Store detection details for display
        self.detection_details = detected_ranges['detection_details']
        self.detection_successful = detected_ranges['detection_successful']
        
        if self.detection_successful:
            print(f"‚úÖ DASHBOARD INITIALIZED WITH AUTO-DETECTED RANGES:")
            print(f"   üí® Gas Injection: [{self.default_actions['gas_inj_min']:.0f}, {self.default_actions['gas_inj_max']:.0f}] ft¬≥/day")
            print(f"   üîΩ Producer BHP: [{self.default_actions['bhp_min']:.2f}, {self.default_actions['bhp_max']:.2f}] psi")
        else:
            print(f"‚ö†Ô∏è DASHBOARD INITIALIZED WITH FALLBACK RANGES:")
            print(f"   üí® Gas Injection: [{self.default_actions['gas_inj_min']:.0f}, {self.default_actions['gas_inj_max']:.0f}] ft¬≥/day")
            print(f"   üîΩ Producer BHP: [{self.default_actions['bhp_min']:.2f}, {self.default_actions['bhp_max']:.2f}] psi")
        
        # ROM compatibility handled through training-only normalization parameters
        
        # Default economic parameters (current values from code)
        self.default_economics = {
            'gas_injection_revenue': 50.0,  # Gas injection credit per ton ($/ton)
            'gas_injection_cost': 10.0,     # Gas injection cost per ton ($/ton)
            'water_production_penalty': 5.0,    # from reward function
            'gas_production_penalty': 50.0, # from reward function
            'lf3_to_ton_conversion': 0.1167 * 4.536e-4,  # from reward function
            'scale_factor': 1000000.0,  # Updated to 1 million for proper RL reward scaling
            'years_before_project_start': 5,  # Years of pre-project development (updated to 5)
            'capital_cost_per_year': 100000000.0,  # Capital cost per year during pre-project phase ($100M default)
            'fixed_capital_cost': 500000000.0  # Calculated: years_before_project_start √ó capital_cost_per_year
        }
        
        # Default RL model hyperparameters
        self.default_rl_hyperparams = {
            'networks': {
                'hidden_dim': 200,
                'policy_type': 'deterministic',
                'output_activation': 'sigmoid'
            },
            'sac': {
                'discount_factor': 0.986,
                'soft_update_tau': 0.005,
                'entropy_alpha': 0.0,
                'critic_lr': 0.0001,
                'policy_lr': 0.0001,
                'gradient_clipping': True,
                'max_norm': 10.0
            },
            'training': {
                'max_episodes': 100,
                'max_steps_per_episode': 30,
                'batch_size': 256,
                'replay_capacity': 100000,
                'initial_exploration': 30
            }
        }
        
        # Default action variation parameters
        self.default_action_variation = {
            'enabled': True,
            'noise_decay_rate': 0.995,
            'max_noise_std': 0.25,
            'min_noise_std': 0.01,
            'step_variation_amplitude': 0.15,
            'mode': 'adaptive',  # 'adaptive', 'exploration', 'exploitation', 'minimal'
            'well_strategies': {
                'P1': {'variation': 0.15, 'bias': 0.0, 'exploration_scale': 0.8},    # Conservative producer
                'P2': {'variation': 0.20, 'bias': 0.05, 'exploration_scale': 1.0},   # Moderate producer  
                'P3': {'variation': 0.30, 'bias': -0.05, 'exploration_scale': 1.3},  # Aggressive producer
                'I1': {'variation': 0.18, 'bias': 0.02, 'exploration_scale': 0.9},   # Conservative injector
                'I2': {'variation': 0.25, 'bias': 0.0, 'exploration_scale': 1.1},    # Moderate injector
                'I3': {'variation': 0.35, 'bias': 0.08, 'exploration_scale': 1.4}    # Aggressive injector
            },
            'enhanced_gaussian_policy': {
                'enabled': False,  # Set to True to use Gaussian instead of deterministic
                'log_std_bounds': [-1.0, 1.0],  # Wider bounds for better exploration
                'entropy_weight': 0.2  # Entropy regularization weight
            }
        }
        

        
        if not WIDGETS_AVAILABLE:
            print("‚ùå Interactive widgets not available. Dashboard cannot be created.")
            return
            
        self._create_widgets()
        self._setup_event_handlers()
    
    # _apply_rom_compatibility method removed - using training-only normalization approach
    
    def _load_preprocessing_normalization_parameters(self):
        """
        Load the EXACT same normalization parameters saved by data preprocessing dashboard
        üéØ PERFECT COMPATIBILITY: Reads identical JSON files
        """
        import json
        import os
        from datetime import datetime
        
        try:
            # Find the most recent normalization parameter file (same logic as RL_SAC_Interactive_Training.py)
            norm_files = [f for f in os.listdir('.') if f.startswith('normalization_parameters_') and f.endswith('.json')]
            
            if not norm_files:
                print(f"      ‚ùå No normalization parameter JSON files found")
                print(f"      üí° Expected files like: normalization_parameters_YYYYMMDD_HHMMSS.json")
                return None
            
            # Get the most recent file
            latest_norm_file = sorted(norm_files)[-1]
            print(f"      üìÇ Loading from: {latest_norm_file}")
            
            # Load the JSON file
            with open(latest_norm_file, 'r') as f:
                preprocessing_params = json.load(f)
            
            # Validate the structure
            expected_keys = ['spatial_channels', 'control_variables', 'observation_variables', 'selection_summary', 'metadata']
            missing_keys = [key for key in expected_keys if key not in preprocessing_params]
            
            if missing_keys:
                print(f"      ‚ö†Ô∏è Warning: Missing keys in normalization file: {missing_keys}")
            
            # Print detailed parameter summary
            print(f"      üìä Loaded preprocessing parameters:")
            print(f"         üìÖ Created: {preprocessing_params.get('metadata', {}).get('created_timestamp', 'unknown')}")
            
            # Spatial channels details
            spatial_channels = preprocessing_params.get('spatial_channels', {})
            if spatial_channels:
                print(f"         üèîÔ∏è Spatial channels ({len(spatial_channels)}):")
                for channel, config in spatial_channels.items():
                    norm_type = config.get('normalization_type', 'unknown')
                    selected = config.get('selected_for_training', False)
                    status = "‚úÖ TRAINING" if selected else "‚≠ï AVAILABLE"
                    print(f"            ‚Ä¢ {channel}: {norm_type.upper()} {status}")
            
            # Control variables details
            control_vars = preprocessing_params.get('control_variables', {})
            if control_vars:
                print(f"         üéõÔ∏è Control variables ({len(control_vars)}):")
                for var, config in control_vars.items():
                    norm_type = config.get('normalization_type', 'unknown')
                    wells = config.get('selected_wells', [])
                    print(f"            ‚Ä¢ {var}: {norm_type.upper()} (wells: {wells})")
            
            # Observation variables details
            obs_vars = preprocessing_params.get('observation_variables', {})
            if obs_vars:
                print(f"         üìä Observation variables ({len(obs_vars)}):")
                for var, config in obs_vars.items():
                    norm_type = config.get('normalization_type', 'unknown')
                    wells = config.get('selected_wells', [])
                    print(f"            ‚Ä¢ {var}: {norm_type.upper()} (wells: {wells})")
            
            # Training channel verification
            selection_summary = preprocessing_params.get('selection_summary', {})
            training_channels = selection_summary.get('training_channels', [])
            if training_channels:
                print(f"         üéØ Training channels: {training_channels}")
            
            print(f"      ‚úÖ Preprocessing parameters loaded successfully from {latest_norm_file}")
            return preprocessing_params
            
        except FileNotFoundError:
            print(f"      ‚ùå Normalization parameter file not found")
            return None
        except json.JSONDecodeError as e:
            print(f"      ‚ùå Error parsing JSON file: {e}")
            return None
        except Exception as e:
            print(f"      ‚ùå Error loading preprocessing parameters: {e}")
            return None
        
    def _create_widgets(self):
        """Create all dashboard widgets"""
        
        # Header
        self.header = widgets.HTML(
            value="<h1>üéÆ RL Configuration Dashboard</h1>",
            layout=widgets.Layout(margin='10px 0px')
        )
        
        # === FOLDER CONFIGURATION ===
        self.folder_section = widgets.VBox([
            widgets.HTML("<h2>üìÅ Folder Configuration</h2>"),
            
            widgets.HBox([
                widgets.Label("ROM Models Folder:", layout=widgets.Layout(width='150px')),
                widgets.Text(
                    value=self.rom_folder,
                    placeholder="Path to ROM models folder",
                    layout=widgets.Layout(width='300px')
                )
            ]),
            
            widgets.HBox([
                widgets.Label("State Data Folder:", layout=widgets.Layout(width='150px')),
                widgets.Text(
                    value=self.state_folder,
                    placeholder="Path to state data folder",
                    layout=widgets.Layout(width='300px')
                )
            ]),
            
            widgets.Button(
                description="üîç Scan Folders",
                button_style='primary',
                layout=widgets.Layout(width='150px')
            )
        ])
        
        # Store references to folder widgets
        self.rom_folder_input = self.folder_section.children[1].children[1]
        self.state_folder_input = self.folder_section.children[2].children[1]
        self.scan_button = self.folder_section.children[3]
        
        # Status output
        self.status_output = widgets.Output()
        
        # === TAB STRUCTURE ===
        self.tabs = widgets.Tab()
        
        # State Tab
        self.state_tab = widgets.VBox([
            widgets.HTML("<h3>üèîÔ∏è State Selection & Scaling</h3>"),
            widgets.HTML("<p><i>Select which states to use and configure their normalization</i></p>")
        ])
        
        # Action Tab
        self.action_tab = widgets.VBox([
            widgets.HTML("<h3>üéÆ Action Range Configuration</h3>"),
            widgets.HTML("<p><i>Configure BHP and injection rate ranges for each well</i></p>")
        ])
        
        # Economic Tab
        self.economic_tab = widgets.VBox([
            widgets.HTML("<h3>üí∞ Economic Parameters</h3>"),
            widgets.HTML("<p><i>Configure NPV calculation parameters</i></p>")
        ])
        
        # RL Hyperparameters Tab
        self.rl_hyperparams_tab = widgets.VBox([
            widgets.HTML("<h3>üß† RL Model Hyperparameters</h3>"),
            widgets.HTML("<p><i>Configure SAC algorithm and network parameters</i></p>")
        ])
        
        # Action Variation Tab
        self.action_variation_tab = widgets.VBox([
            widgets.HTML("<h3>üåä Action Variation Enhancement</h3>"),
            widgets.HTML("<p><i>Configure advanced action variation strategies for wide exploration</i></p>")
        ])
        
        # Set up tabs
        self.tabs.children = [self.state_tab, self.action_tab, self.economic_tab, self.rl_hyperparams_tab, self.action_variation_tab]
        self.tabs.set_title(0, "üèîÔ∏è States")
        self.tabs.set_title(1, "üéÆ Actions")
        self.tabs.set_title(2, "üí∞ Economics")
        self.tabs.set_title(3, "üß† RL Hyperparams")
        self.tabs.set_title(4, "üåä Variation")
        
        # === CONTROL BUTTONS ===
        self.control_buttons = widgets.HBox([
            widgets.Button(
                description="‚úÖ Apply Configuration",
                button_style='success',
                layout=widgets.Layout(width='200px')
            ),
            widgets.Button(
                description="üîÑ Reset to Defaults",
                button_style='warning',
                layout=widgets.Layout(width='150px')
            ),
            widgets.Button(
                description="üíæ Save Config",
                button_style='info',
                layout=widgets.Layout(width='120px')
            )
        ])
        
        self.apply_button = self.control_buttons.children[0]
        self.reset_button = self.control_buttons.children[1]
        self.save_button = self.control_buttons.children[2]
        
        # Results output
        self.results_output = widgets.Output()
        
        # === MAIN LAYOUT ===
        self.main_widget = widgets.VBox([
            self.header,
            self.folder_section,
            self.status_output,
            self.tabs,
            self.control_buttons,
            self.results_output
        ])
        
    def _setup_event_handlers(self):
        """Setup event handlers for widgets"""
        self.scan_button.on_click(self._scan_folders)
        self.apply_button.on_click(self._apply_configuration)
        self.reset_button.on_click(self._reset_defaults)
        self.save_button.on_click(self._save_configuration)
        
    def _scan_folders(self, button):
        """Scan folders for ROM models and state data"""
        with self.status_output:
            clear_output(wait=True)
            
            self.rom_folder = self.rom_folder_input.value.strip()
            self.state_folder = self.state_folder_input.value.strip()
            
            print(f"üîç Scanning ROM folder: {self.rom_folder}")
            print(f"üîç Scanning state folder: {self.state_folder}")
            
            # Scan ROM models
            self._scan_rom_models()
            
            # Scan available states
            self._scan_available_states()
            
            # Re-detect action ranges with updated folder path
            print("\nüîÑ RE-DETECTING ACTION RANGES WITH UPDATED FOLDER PATH...")
            detected_ranges = auto_detect_action_ranges_from_h5(data_dir=self.state_folder)
            
            # Update default actions
            self.default_actions = {
                'bhp_min': detected_ranges['bhp_min'],
                'bhp_max': detected_ranges['bhp_max'],
                'gas_inj_min': detected_ranges['gas_inj_min'],
                'gas_inj_max': detected_ranges['gas_inj_max']
            }
            
            # Update detection details
            self.detection_details = detected_ranges['detection_details']
            self.detection_successful = detected_ranges['detection_successful']
            
            # Update tabs
            self._update_state_tab()
            self._update_action_tab()
            self._update_economic_tab()
            self._update_rl_hyperparams_tab()
            self._update_action_variation_tab()
            
            print("‚úÖ Folder scanning completed!")
    
    def _scan_rom_models(self):
        """Scan for available ROM models"""
        rom_models = []
        
        if not os.path.exists(self.rom_folder):
            print(f"‚ùå ROM folder not found: {self.rom_folder}")
            return
        
        # Normalize path
        rom_folder = os.path.normpath(self.rom_folder)
        
        # Look for encoder files to identify ROM models
        # Support both grid search pattern (e2co_encoder_grid_*) and standard pattern (e2co_encoder_*)
        encoder_patterns = [
            os.path.join(rom_folder, "e2co_encoder_grid_*.h5"),  # Grid search pattern
            os.path.join(rom_folder, "e2co_encoder_*.h5"),        # Standard pattern
            os.path.join(rom_folder, "*encoder*.h5")              # Fallback pattern
        ]
        
        encoder_files = []
        for pattern in encoder_patterns:
            encoder_files.extend(glob.glob(pattern))
        
        # Remove duplicates
        encoder_files = list(set(encoder_files))
        
        if not encoder_files:
            print(f"   ‚ö†Ô∏è No encoder files found in {rom_folder}")
            print(f"   üí° Looking for files matching: e2co_encoder_*.h5 or *encoder*.h5")
            self.config['rom_models'] = []
            return
        
        print(f"   üîç Found {len(encoder_files)} encoder files")
        
        # Group encoder/decoder/transition files by their base pattern
        model_groups = {}
        
        for encoder_file in encoder_files:
            filename = os.path.basename(encoder_file)
            dirname = os.path.dirname(encoder_file)
            
            # Extract base pattern - everything except the component name
            # For grid pattern: e2co_encoder_grid_bs32_ld32_ns2_run0001_bs32_ld32_ns2.h5
            # Base: e2co_grid_bs32_ld32_ns2_run0001_bs32_ld32_ns2.h5
            # For standard pattern: e2co_encoder_3D_native_nt800_l128_lr1e-04_ep200_steps2_channels2_wells6.h5
            # Base: e2co_3D_native_nt800_l128_lr1e-04_ep200_steps2_channels2_wells6.h5
            
            # Try to find matching decoder and transition files
            decoder_file = None
            transition_file = None
            
            # Method 1: Replace encoder with decoder/transition
            decoder_candidate1 = os.path.join(dirname, filename.replace('_encoder', '_decoder'))
            transition_candidate1 = os.path.join(dirname, filename.replace('_encoder', '_transition'))
            
            # Method 2: For grid pattern, replace encoder_grid with decoder_grid/transition_grid
            decoder_candidate2 = os.path.join(dirname, filename.replace('encoder_grid', 'decoder_grid'))
            transition_candidate2 = os.path.join(dirname, filename.replace('encoder_grid', 'transition_grid'))
            
            # Check which method works
            if os.path.exists(decoder_candidate1):
                decoder_file = decoder_candidate1
            elif os.path.exists(decoder_candidate2):
                decoder_file = decoder_candidate2
            
            if os.path.exists(transition_candidate1):
                transition_file = transition_candidate1
            elif os.path.exists(transition_candidate2):
                transition_file = transition_candidate2
            
            # If we found all three files, add to models
            if decoder_file and transition_file:
                # Extract model info from filename
                model_info = self._parse_model_filename(filename)
                
                # Create a display name
                display_name = self._create_model_display_name(filename, model_info)
                
                # Use base pattern as key to avoid duplicates
                base_pattern = filename.replace('_encoder', '').replace('encoder_grid', 'grid')
                
                if base_pattern not in model_groups:
                    model_groups[base_pattern] = {
                        'name': display_name,
                        'encoder': encoder_file,
                        'decoder': decoder_file,
                        'transition': transition_file,
                        'info': model_info,
                        'filename': filename
                    }
        
        # Convert to list
        rom_models = list(model_groups.values())
        
        # Sort by run number or epoch if available
        def sort_key(model):
            info = model.get('info', {})
            # Prefer run number, then epoch, then latent dim
            run_num = info.get('run', 0)
            epoch = info.get('epoch', 0)
            latent = info.get('latent', 0)
            return (run_num, epoch, latent)
        
        rom_models.sort(key=sort_key, reverse=True)
        
        self.config['rom_models'] = rom_models
        print(f"üìä Found {len(rom_models)} complete ROM model sets")
        
        for i, model in enumerate(rom_models):
            info = model['info']
            print(f"   {i+1}. {model['name']}")
            if info:
                details = []
                if 'batch_size' in info:
                    details.append(f"bs={info['batch_size']}")
                if 'latent' in info:
                    details.append(f"ld={info['latent']}")
                if 'run' in info:
                    details.append(f"run={info['run']}")
                if 'epoch' in info:
                    details.append(f"ep={info['epoch']}")
                if details:
                    print(f"      ({', '.join(details)})")
    
    def _create_model_display_name(self, filename, model_info):
        """Create a user-friendly display name for the model"""
        # For grid search models: e2co_encoder_grid_bs32_ld32_ns2_run0001_bs32_ld32_ns2.h5
        # Display: Grid Model (bs=32, ld=32, run=1)
        
        # For standard models: e2co_encoder_3D_native_nt800_l128_lr1e-04_ep200_steps2_channels2_wells6.h5
        # Display: Standard Model (ld=128, ep=200, ch=2)
        
        if 'grid' in filename.lower():
            parts = []
            if 'batch_size' in model_info:
                parts.append(f"bs={model_info['batch_size']}")
            if 'latent' in model_info:
                parts.append(f"ld={model_info['latent']}")
            if 'run' in model_info:
                parts.append(f"run={model_info['run']}")
            if parts:
                return f"Grid Model ({', '.join(parts)})"
            else:
                return "Grid Search Model"
        else:
            parts = []
            if 'latent' in model_info:
                parts.append(f"ld={model_info['latent']}")
            if 'epoch' in model_info:
                parts.append(f"ep={model_info['epoch']}")
            if 'channels' in model_info:
                parts.append(f"ch={model_info['channels']}")
            if parts:
                return f"Standard Model ({', '.join(parts)})"
            else:
                return os.path.basename(filename).replace('_encoder', '').replace('.h5', '')
    
    def _parse_model_filename(self, filename):
        """Parse model filename to extract configuration info"""
        info = {}
        
        # Extract parameters using regex
        # Support both grid search pattern and standard pattern
        patterns = {
            'channels': r'channels(\d+)',
            'epoch': r'ep(\d+)',
            'latent': r'[^a-zA-Z]l(\d+)[^a-zA-Z]',  # Match 'l' followed by digits, avoiding 'ld' confusion
            'latent_dim': r'ld(\d+)',  # Explicit latent dimension pattern
            'wells': r'wells(\d+)',
            'steps': r'steps(\d+)',
            'nsteps': r'ns(\d+)',  # Grid search uses 'ns' for nsteps
            'batch_size': r'bs(\d+)',  # Grid search uses 'bs' for batch_size
            'run': r'run(\d+)',  # Grid search run number
            'num_train': r'nt(\d+)',  # Number of training samples
            'learning_rate': r'lr([\d\.e\-]+)',  # Learning rate (may be scientific notation)
        }
        
        for param, pattern in patterns.items():
            match = re.search(pattern, filename)
            if match:
                try:
                    if param == 'learning_rate':
                        # Handle scientific notation
                        val_str = match.group(1)
                        info[param] = float(val_str)
                    else:
                        info[param] = int(match.group(1))
                except (ValueError, IndexError):
                    pass
        
        # Normalize latent dimension (prefer latent_dim over latent)
        if 'latent_dim' in info:
            info['latent'] = info['latent_dim']
        elif 'latent' not in info and 'l' in filename:
            # Try to extract from 'l' pattern if not found
            match = re.search(r'_l(\d+)_', filename)
            if match:
                info['latent'] = int(match.group(1))
        
        return info
    
    def _scan_available_states(self):
        """Scan for available state data files"""
        available_states = []
        
        if not os.path.exists(self.state_folder):
            print(f"‚ùå State folder not found: {self.state_folder}")
            return
            
        # Look for spatial property files
        for state_name in self.known_states:
            state_file = os.path.join(self.state_folder, f'batch_spatial_properties_{state_name}.h5')
            if os.path.exists(state_file):
                available_states.append(state_name)
                print(f"   ‚úÖ Found {state_name} data")
        
        self.config['available_states'] = available_states
        print(f"üìä Found {len(available_states)} state types: {available_states}")
    
    def _get_min_positive_value(self, state_name):
        """Get minimum positive value for a state"""
        try:
            state_file = os.path.join(self.state_folder, f'batch_spatial_properties_{state_name}.h5')
            if os.path.exists(state_file):
                with h5py.File(state_file, 'r') as hf:
                    data = np.array(hf['data'])
                    positive_data = data[data > 0]
                    if len(positive_data) > 0:
                        return float(np.min(positive_data))
                    else:
                        return 0.0
            else:
                return 0.0
        except Exception as e:
            print(f"Error reading {state_name}: {e}")
            return 0.0
        
    def _update_state_tab(self):
        """Update the state selection tab"""
        if not self.config['available_states']:
            self.state_tab.children = [
                widgets.HTML("<h3>üèîÔ∏è State Selection & Scaling</h3>"),
                widgets.HTML("<p>‚ùå No state data found. Please check the state folder path.</p>")
            ]
            return
            
        state_widgets = [
            widgets.HTML("<h3>üèîÔ∏è State Selection & Scaling</h3>"),
            widgets.HTML("<p><i>Select states and configure normalization. Min values use minimum positive (>0) values.</i></p>")
        ]
        
        # ROM model selection
        if self.config['rom_models']:
            # Create user-friendly options with detailed info
            rom_options = []
            for i, m in enumerate(self.config['rom_models']):
                info = m.get('info', {})
                display_name = m.get('name', f"Model {i+1}")
                
                # Add additional details if available
                details = []
                if 'batch_size' in info:
                    details.append(f"bs={info['batch_size']}")
                if 'latent' in info:
                    details.append(f"ld={info['latent']}")
                if 'channels' in info:
                    details.append(f"ch={info['channels']}")
                if 'run' in info:
                    details.append(f"run={info['run']}")
                if 'epoch' in info:
                    details.append(f"ep={info['epoch']}")
                
                if details:
                    full_name = f"{display_name} ({', '.join(details)})"
                else:
                    full_name = display_name
                
                rom_options.append((full_name, i))
            
            self.rom_selector = widgets.Dropdown(
                options=rom_options,
                description='ROM Model:',
                style={'description_width': '120px'},
                layout=widgets.Layout(width='600px')
            )
            
            # Add info about selected model
            def on_rom_selection_change(change):
                if change['new'] is not None:
                    selected_idx = change['new']
                    if selected_idx < len(self.config['rom_models']):
                        selected_model = self.config['rom_models'][selected_idx]
                        encoder_file = os.path.basename(selected_model['encoder'])
                        print(f"   üìå Selected: {selected_model['name']}")
                        print(f"      File: {encoder_file}")
            
            self.rom_selector.observe(on_rom_selection_change, names='value')
            
            state_widgets.append(self.rom_selector)
            
            # Add instruction text
            state_widgets.append(widgets.HTML(
                "<p><i>üí° Select a ROM model from the dropdown above. "
                "Make sure the model's configuration matches your RL setup.</i></p>"
            ))
        
        # State selection and scaling
        state_widgets.append(widgets.HTML("<hr><h4>üìä State Selection & Scaling</h4>"))
        
        self.state_checkboxes = {}
        self.scaling_radios = {}
        
        for state_name in self.config['available_states']:
            # State checkbox - use ROM compatibility if available
            if hasattr(self, 'rom_normalization') and state_name in self.rom_normalization:
                default_selected = True  # ROM states are automatically selected
            else:
                default_selected = state_name in ['SG', 'PRES']  # Fallback to common states (SW unchecked by default)
            
            checkbox = widgets.Checkbox(
                value=default_selected,
                description=f'{state_name}',
                style={'description_width': 'initial'},
                layout=widgets.Layout(width='100px')
            )
            
            # Scaling options - use ROM scaling if available
            if hasattr(self, 'rom_state_scaling') and state_name in self.rom_state_scaling:
                default_scaling = self.rom_state_scaling[state_name]
            else:
                default_scaling = 'log' if 'PERM' in state_name else 'minmax'  # Fallback
            
            scaling_radio = widgets.RadioButtons(
                options=['minmax', 'log'],
                value=default_scaling,
                layout=widgets.Layout(width='150px')
            )
            
            # Min positive value info
            min_pos = self._get_min_positive_value(state_name)
            info_label = widgets.HTML(
                value=f"<small>Min+: {min_pos:.6f}</small>",
                layout=widgets.Layout(width='120px')
            )
            
            state_row = widgets.HBox([
                checkbox,
                widgets.Label('Scaling:', layout=widgets.Layout(width='60px')),
                scaling_radio,
                info_label
            ])
            
            state_widgets.append(state_row)
            
            self.state_checkboxes[state_name] = checkbox
            self.scaling_radios[state_name] = scaling_radio
        
        self.state_tab.children = state_widgets
    
    def _update_action_tab(self):
        """Update the action configuration tab"""
        action_widgets = [
            widgets.HTML("<h3>üéÆ Action Range Configuration</h3>"),
            widgets.HTML("<p><i>Configure BHP and injection rate ranges for each well</i></p>")
        ]
        
        # Add detection status information
        if hasattr(self, 'detection_successful') and self.detection_successful:
            detection_html = "<div style='background-color: #e8f5e8; padding: 10px; border-left: 4px solid #4CAF50; margin: 10px 0;'>"
            detection_html += "<h4>‚úÖ Auto-Detected Ranges from H5 Files</h4>"
            detection_html += "<p><b>Ranges below are automatically detected from your data files:</b></p>"
            
            if 'gas' in self.detection_details:
                gas_details = self.detection_details['gas']
                detection_html += f"<p>üí® <b>Gas Injection:</b> [{gas_details['min']:.0f}, {gas_details['max']:.0f}] ft¬≥/day<br/>"
                detection_html += f"&nbsp;&nbsp;&nbsp;&nbsp;üìÇ Source: {gas_details['source']} (shape: {gas_details['shape']})</p>"
            
            if 'bhp' in self.detection_details:
                bhp_details = self.detection_details['bhp']
                detection_html += f"<p>üîΩ <b>Producer BHP:</b> [{bhp_details['min']:.2f}, {bhp_details['max']:.2f}] psi<br/>"
                detection_html += f"&nbsp;&nbsp;&nbsp;&nbsp;üìÇ Source: {bhp_details['source']} (shape: {bhp_details['producer_shape']})</p>"
            
            detection_html += "<p><i>üí° These ranges reflect the actual data in your reservoir model and are optimal for RL training.</i></p>"
            detection_html += "</div>"
            
            action_widgets.append(widgets.HTML(detection_html))
        else:
            fallback_html = "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin: 10px 0;'>"
            fallback_html += "<h4>‚ö†Ô∏è Using Fallback Default Ranges</h4>"
            fallback_html += "<p><b>Auto-detection failed. Using predefined ranges:</b></p>"
            fallback_html += f"<p>üí® Gas Injection: [{self.default_actions['gas_inj_min']:.0f}, {self.default_actions['gas_inj_max']:.0f}] ft¬≥/day</p>"
            fallback_html += f"<p>üîΩ Producer BHP: [{self.default_actions['bhp_min']:.2f}, {self.default_actions['bhp_max']:.2f}] psi</p>"
            fallback_html += "<p><i>üí° Check that H5 files exist in sr3_batch_output/ directory.</i></p>"
            fallback_html += "</div>"
            
            action_widgets.append(widgets.HTML(fallback_html))
        
        # Add refresh button for re-detection
        refresh_button = widgets.Button(
            description="üîÑ Re-detect Ranges",
            button_style='info',
            tooltip="Re-scan H5 files to detect action ranges",
            layout=widgets.Layout(width='150px', margin='10px 0px')
        )
        refresh_button.on_click(self._refresh_action_ranges)
        action_widgets.append(refresh_button)
        
        # Well configuration
        self.num_wells_input = widgets.IntSlider(
            value=6,
            min=2,
            max=20,
            description='Total Wells:',
            style={'description_width': '100px'},
            layout=widgets.Layout(width='300px')
        )
        
        self.num_prod_input = widgets.IntSlider(
            value=3,
            min=1,
            max=10,
            description='Producers:',
            style={'description_width': '100px'},
            layout=widgets.Layout(width='300px')
        )
        
        action_widgets.extend([
            widgets.HTML("<h4>üè≠ Well Configuration</h4>"),
            self.num_wells_input,
            self.num_prod_input
        ])
        
        # BHP ranges for producers
        action_widgets.append(widgets.HTML("<h4>üìä BHP Ranges (psi) - Producers</h4>"))
        
        self.bhp_ranges = {}
        for i in range(3):  # Default 3 producers
            min_input = widgets.FloatText(
                value=self.default_actions['bhp_min'],
                description=f'P{i+1} Min:',
                style={'description_width': '80px'},
                layout=widgets.Layout(width='150px')
            )
            max_input = widgets.FloatText(
                value=self.default_actions['bhp_max'],
                description=f'Max:',
                style={'description_width': '40px'},
                layout=widgets.Layout(width='120px')
            )
            
            row = widgets.HBox([min_input, max_input])
            action_widgets.append(row)
            
            self.bhp_ranges[f'P{i+1}'] = {'min': min_input, 'max': max_input}
        
        # Gas injection ranges for injectors
        action_widgets.append(widgets.HTML("<h4>‚õΩ Gas Injection Ranges (ft¬≥/day) - Injectors</h4>"))
        
        self.gas_ranges = {}
        for i in range(3):  # Default 3 injectors
            min_input = widgets.FloatText(
                value=self.default_actions['gas_inj_min'],
                description=f'I{i+1} Min:',
                style={'description_width': '80px'},
                layout=widgets.Layout(width='180px')
            )
            max_input = widgets.FloatText(
                value=self.default_actions['gas_inj_max'],
                description=f'Max:',
                style={'description_width': '40px'},
                layout=widgets.Layout(width='180px')
            )
            
            row = widgets.HBox([min_input, max_input])
            action_widgets.append(row)
            
            self.gas_ranges[f'I{i+1}'] = {'min': min_input, 'max': max_input}
        
        self.action_tab.children = action_widgets
    
    def _refresh_action_ranges(self, button):
        """Re-detect action ranges from H5 files and update the dashboard"""
        print("üîÑ RE-DETECTING ACTION RANGES...")
        
        # Get current state folder
        current_state_folder = self.state_folder_input.value.strip() if hasattr(self, 'state_folder_input') else self.state_folder
        
        # Re-run detection
        detected_ranges = auto_detect_action_ranges_from_h5(data_dir=current_state_folder)
        
        # Update default actions
        self.default_actions = {
            'bhp_min': detected_ranges['bhp_min'],
            'bhp_max': detected_ranges['bhp_max'],
            'gas_inj_min': detected_ranges['gas_inj_min'],
            'gas_inj_max': detected_ranges['gas_inj_max']
        }
        
        # Update detection details
        self.detection_details = detected_ranges['detection_details']
        self.detection_successful = detected_ranges['detection_successful']
        
        # Update the action widgets with new values
        if hasattr(self, 'bhp_ranges'):
            for well_ranges in self.bhp_ranges.values():
                well_ranges['min'].value = self.default_actions['bhp_min']
                well_ranges['max'].value = self.default_actions['bhp_max']
        
        if hasattr(self, 'gas_ranges'):
            for well_ranges in self.gas_ranges.values():
                well_ranges['min'].value = self.default_actions['gas_inj_min']
                well_ranges['max'].value = self.default_actions['gas_inj_max']
        
        # Refresh the entire action tab to show updated detection status
        self._update_action_tab()
        
        print("‚úÖ Action ranges refreshed successfully!")
    
    def _update_economic_tab(self):
        """Update the economic parameters tab"""
        economic_widgets = [
            widgets.HTML("<h3>üí∞ Economic Parameters</h3>"),
            widgets.HTML("<p><i>Configure NPV calculation parameters for reward function</i></p>")
        ]
        
        # Economic parameter inputs
        self.economic_inputs = {}
        
        params = [
            ('gas_injection_revenue', 'Gas Injection Credit ($/ton)', self.default_economics['gas_injection_revenue']),
            ('gas_injection_cost', 'Gas Injection Cost ($/ton)', self.default_economics['gas_injection_cost']),
            ('water_production_penalty', 'Water Production Penalty ($/barrel)', self.default_economics['water_production_penalty']),
            ('gas_production_penalty', 'Gas Production Penalty ($/ton)', self.default_economics['gas_production_penalty']),
            ('lf3_to_ton_conversion', 'ft¬≥ to ton Conversion Factor', self.default_economics['lf3_to_ton_conversion']),
            ('scale_factor', 'Scale Factor', self.default_economics['scale_factor'])
        ]
        
        # Add pre-project development parameters section
        economic_widgets.append(widgets.HTML("<hr><h4>üèóÔ∏è Pre-Project Development Phase</h4>"))
        
        # Years before project start
        self.years_before_input = widgets.IntText(
            value=self.default_economics['years_before_project_start'],
            description='Years before project start:',
            style={'description_width': '250px'},
            layout=widgets.Layout(width='450px')
        )
        economic_widgets.append(self.years_before_input)
        
        # Capital cost per year
        self.capital_per_year_input = widgets.FloatText(
            value=self.default_economics['capital_cost_per_year'],
            description='Capital cost per year ($):',
            style={'description_width': '250px'},
            layout=widgets.Layout(width='450px')
        )
        economic_widgets.append(self.capital_per_year_input)
        
        # Total capital cost (calculated automatically)
        self.total_capital_display = widgets.HTML(
            value=f"<b>Total Capital Cost: ${self.default_economics['fixed_capital_cost']:,.0f}</b>",
            layout=widgets.Layout(width='450px')
        )
        economic_widgets.append(self.total_capital_display)
        
        # Store references for calculation
        self.economic_inputs['years_before_project_start'] = self.years_before_input
        self.economic_inputs['capital_cost_per_year'] = self.capital_per_year_input
        
        # Set up automatic calculation
        def update_total_capital(*args):
            years = self.years_before_input.value
            cost_per_year = self.capital_per_year_input.value
            total_cost = years * cost_per_year
            self.total_capital_display.value = f"<b>Total Capital Cost: ${total_cost:,.0f}</b>"
        
        self.years_before_input.observe(update_total_capital, names='value')
        self.capital_per_year_input.observe(update_total_capital, names='value')
        
        # Add operational parameters section
        economic_widgets.append(widgets.HTML("<hr><h4>üíº Operational Parameters</h4>"))
        
        # Add operational parameters
        operational_params = [
            ('fixed_capital_cost', 'Fixed Capital Cost (calculated above)', self.default_economics['fixed_capital_cost'])
        ]
        
        for param_key, param_label, param_default in params:
            input_widget = widgets.FloatText(
                value=param_default,
                description=param_label,
                style={'description_width': '250px'},
                layout=widgets.Layout(width='450px')
            )
            
            economic_widgets.append(input_widget)
            self.economic_inputs[param_key] = input_widget
        
        # Add calculated capital cost as read-only display (not editable)
        self.economic_inputs['fixed_capital_cost'] = widgets.HTML(
            value=f"${self.default_economics['fixed_capital_cost']:,.0f}",
            description='Total Capital Cost (calculated):',
            layout=widgets.Layout(width='450px')
        )
        
        # Current reward function display
        economic_widgets.extend([
            widgets.HTML("<hr><h4>Current Reward Function</h4>"),
            widgets.HTML("""
            <div style='background-color: #f0f8ff; padding: 10px; border-left: 4px solid #4CAF50;'>
            <pre>
PV = (gas_revenue * conversion * injection_rates
      - gas_cost * conversion * injection_rates
      - water_penalty * water_production 
      - gas_penalty * conversion * gas_production) / scale_factor

Where:
- gas_revenue: Revenue from gas injection ($/ton)
- gas_cost: Cost of gas injection ($/ton)
- water_penalty: Penalty for water production ($/barrel)  
- gas_penalty: Penalty for gas production ($/ton)
- conversion: ft¬≥ to ton conversion factor
- scale_factor: Numerical scaling
            </pre>
            </div>
            """)
        ])
        
        self.economic_tab.children = economic_widgets
    
    def _update_rl_hyperparams_tab(self):
        """Update the RL hyperparameters configuration tab"""
        hyperparam_widgets = [
            widgets.HTML("<h3>üß† RL Model Hyperparameters</h3>"),
            widgets.HTML("<p><i>Configure SAC algorithm and neural network parameters</i></p>")
        ]
        
        # Neural Network Configuration
        hyperparam_widgets.append(widgets.HTML("<hr><h4>üîó Neural Network Architecture</h4>"))
        
        self.rl_hyperparams = {}
        
        # Hidden dimension
        self.rl_hyperparams['hidden_dim'] = widgets.IntSlider(
            value=self.default_rl_hyperparams['networks']['hidden_dim'],
            min=64, max=512, step=64,
            description='Hidden Dim:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['hidden_dim'])
        
        # Policy type
        self.rl_hyperparams['policy_type'] = widgets.Dropdown(
            options=['deterministic', 'gaussian'],
            value=self.default_rl_hyperparams['networks']['policy_type'],
            description='Policy Type:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='300px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['policy_type'])
        
        # Output activation
        self.rl_hyperparams['output_activation'] = widgets.Dropdown(
            options=['sigmoid', 'tanh'],
            value=self.default_rl_hyperparams['networks']['output_activation'],
            description='Output Activation:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='300px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['output_activation'])
        
        # SAC Algorithm Parameters
        hyperparam_widgets.append(widgets.HTML("<hr><h4>üéØ SAC Algorithm Parameters</h4>"))
        
        # Discount factor
        self.rl_hyperparams['discount_factor'] = widgets.FloatSlider(
            value=self.default_rl_hyperparams['sac']['discount_factor'],
            min=0.9, max=0.999, step=0.001,
            description='Discount Factor:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['discount_factor'])
        
        # Soft update tau
        self.rl_hyperparams['soft_update_tau'] = widgets.FloatLogSlider(
            value=self.default_rl_hyperparams['sac']['soft_update_tau'],
            base=10, min=-4, max=-1,
            description='Soft Update œÑ:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['soft_update_tau'])
        
        # Entropy alpha
        self.rl_hyperparams['entropy_alpha'] = widgets.FloatSlider(
            value=self.default_rl_hyperparams['sac']['entropy_alpha'],
            min=0.0, max=1.0, step=0.01,
            description='Entropy Œ±:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['entropy_alpha'])
        
        # Learning rates
        hyperparam_widgets.append(widgets.HTML("<h5>üìö Learning Rates</h5>"))
        
        self.rl_hyperparams['critic_lr'] = widgets.FloatLogSlider(
            value=self.default_rl_hyperparams['sac']['critic_lr'],
            base=10, min=-5, max=-2,
            description='Critic LR:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['critic_lr'])
        
        self.rl_hyperparams['policy_lr'] = widgets.FloatLogSlider(
            value=self.default_rl_hyperparams['sac']['policy_lr'],
            base=10, min=-5, max=-2,
            description='Policy LR:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['policy_lr'])
        
        # Environment Prediction Mode Configuration
        hyperparam_widgets.append(widgets.HTML("<hr><h4>üî¨ Environment Prediction Mode</h4>"))
        
        # Prediction mode selection
        self.rl_hyperparams['prediction_mode'] = widgets.RadioButtons(
            options=[
                ('State-based (Default - E2C Training Workflow)', 'state_based'),
                ('Latent-based (Faster - Pure Latent Evolution)', 'latent_based')
            ],
            value='state_based',  # Default to E2C workflow mode
            description='Prediction Mode:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='500px')
        )
        
        hyperparam_widgets.append(widgets.HTML(
            "<p><b>State-based:</b> Follows E2C training workflow (Spatial‚ÜíLatent‚ÜíSpatial cycle)<br/>"
            "<b>Latent-based:</b> Pure latent evolution (stays in latent space, faster)</p>"
        ))
        hyperparam_widgets.append(self.rl_hyperparams['prediction_mode'])
        
        # Training Configuration
        hyperparam_widgets.append(widgets.HTML("<hr><h4>üèãÔ∏è Training Configuration</h4>"))
        
        # Max episodes
        self.rl_hyperparams['max_episodes'] = widgets.IntSlider(
            value=self.default_rl_hyperparams['training']['max_episodes'],
            min=100, max=5000, step=100,
            description='Max Episodes:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['max_episodes'])
        
        # Max steps per episode
        self.rl_hyperparams['max_steps_per_episode'] = widgets.IntSlider(
            value=self.default_rl_hyperparams['training']['max_steps_per_episode'],
            min=30, max=500, step=10,
            description='Max Steps/Episode:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['max_steps_per_episode'])
        
        # Batch size
        self.rl_hyperparams['batch_size'] = widgets.Dropdown(
            options=[32, 64, 128, 256, 512],
            value=self.default_rl_hyperparams['training']['batch_size'],
            description='Batch Size:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='300px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['batch_size'])
        
        # Replay memory capacity
        self.rl_hyperparams['replay_capacity'] = widgets.Dropdown(
            options=[10000, 50000, 100000, 500000, 1000000],
            value=self.default_rl_hyperparams['training']['replay_capacity'],
            description='Replay Capacity:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='300px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['replay_capacity'])
        
        # Gradient clipping
        hyperparam_widgets.append(widgets.HTML("<h5>‚úÇÔ∏è Gradient Clipping</h5>"))
        
        self.rl_hyperparams['gradient_clipping'] = widgets.Checkbox(
            value=self.default_rl_hyperparams['sac']['gradient_clipping'],
            description='Enable Gradient Clipping',
            style={'description_width': 'initial'},
            layout=widgets.Layout(width='300px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['gradient_clipping'])
        
        self.rl_hyperparams['max_norm'] = widgets.FloatSlider(
            value=self.default_rl_hyperparams['sac']['max_norm'],
            min=1.0, max=50.0, step=1.0,
            description='Max Norm:',
            style={'description_width': '150px'},
            layout=widgets.Layout(width='400px')
        )
        hyperparam_widgets.append(self.rl_hyperparams['max_norm'])
        
        self.rl_hyperparams_tab.children = hyperparam_widgets
    
    def _update_action_variation_tab(self):
        """Create action variation configuration widgets"""
        
        variation_content = []
        
        # Main enable/disable toggle
        variation_content.extend([
            widgets.HTML("<h4>üåä Enable Action Variation Enhancement</h4>"),
            widgets.Checkbox(
                value=self.default_action_variation['enabled'],
                description="Enable Wide Action Variation",
                style={'description_width': 'initial'}
            )
        ])
        
        # Variation mode selection
        variation_content.extend([
            widgets.HTML("<h4>üéØ Variation Mode</h4>"),
            widgets.Dropdown(
                options=[
                    ('Adaptive (Recommended)', 'adaptive'),
                    ('High Exploration', 'exploration'),
                    ('Balanced', 'exploitation'),
                    ('Minimal Variation', 'minimal')
                ],
                value=self.default_action_variation['mode'],
                description="Variation Strategy:",
                style={'description_width': 'initial'}
            ),
            widgets.HTML("<p><i>Adaptive: Changes variation based on training progress</i></p>")
        ])
        
        # Noise parameters
        variation_content.extend([
            widgets.HTML("<h4>üîä Noise Parameters</h4>"),
            widgets.HBox([
                widgets.Label("Max Noise:", layout=widgets.Layout(width='100px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['max_noise_std'],
                    min=0.05, max=0.5, step=0.05,
                    description="",
                    layout=widgets.Layout(width='200px')
                ),
                widgets.Label("(Strong initial exploration)", layout=widgets.Layout(width='200px'))
            ]),
            widgets.HBox([
                widgets.Label("Min Noise:", layout=widgets.Layout(width='100px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['min_noise_std'],
                    min=0.001, max=0.1, step=0.005,
                    description="",
                    layout=widgets.Layout(width='200px')
                ),
                widgets.Label("(Final exploration level)", layout=widgets.Layout(width='200px'))
            ]),
            widgets.HBox([
                widgets.Label("Decay Rate:", layout=widgets.Layout(width='100px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['noise_decay_rate'],
                    min=0.990, max=0.999, step=0.001,
                    description="",
                    layout=widgets.Layout(width='200px')
                ),
                widgets.Label("(How fast noise decreases)", layout=widgets.Layout(width='200px'))
            ])
        ])
        
        # Step variation
        variation_content.extend([
            widgets.HTML("<h4>üìà Step-wise Variation</h4>"),
            widgets.HBox([
                widgets.Label("Amplitude:", layout=widgets.Layout(width='100px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['step_variation_amplitude'],
                    min=0.0, max=0.3, step=0.02,
                    description="",
                    layout=widgets.Layout(width='200px')
                ),
                widgets.Label("(Variation within episodes)", layout=widgets.Layout(width='200px'))
            ])
        ])
        
        # Well-specific strategies configuration
        variation_content.extend([
            widgets.HTML("<h4>üè≠ Well-Specific Strategies</h4>"),
            widgets.HTML("<p><i>Different exploration strategies for each well</i></p>")
        ])
        
        # Create well strategy widgets
        well_widgets = []
        for well_name, strategy in self.default_action_variation['well_strategies'].items():
            well_type = "Producer" if well_name.startswith('P') else "Injector"
            
            well_box = widgets.VBox([
                widgets.HTML(f"<b>{well_name} ({well_type})</b>"),
                widgets.HBox([
                    widgets.Label("Variation:", layout=widgets.Layout(width='80px')),
                    widgets.FloatSlider(
                        value=strategy['variation'],
                        min=0.05, max=0.5, step=0.05,
                        description="",
                        layout=widgets.Layout(width='150px')
                    ),
                    widgets.Label("Bias:", layout=widgets.Layout(width='40px')),
                    widgets.FloatSlider(
                        value=strategy['bias'],
                        min=-0.1, max=0.1, step=0.01,
                        description="",
                        layout=widgets.Layout(width='150px')
                    )
                ])
            ])
            well_widgets.append(well_box)
        
        # Create 2x3 grid for wells
        well_grid = widgets.GridBox(
            well_widgets,
            layout=widgets.Layout(
                width='100%',
                grid_template_columns='repeat(3, 1fr)',
                grid_gap='10px'
            )
        )
        variation_content.append(well_grid)
        
        # Enhanced Gaussian Policy section
        variation_content.extend([
            widgets.HTML("<h4>üé≤ Enhanced Gaussian Policy (Advanced)</h4>"),
            widgets.Checkbox(
                value=self.default_action_variation['enhanced_gaussian_policy']['enabled'],
                description="Use Gaussian Policy instead of Deterministic",
                style={'description_width': 'initial'}
            ),
            widgets.HTML("<p><i>Gaussian policy provides natural stochasticity for exploration</i></p>"),
            widgets.HBox([
                widgets.Label("Log Std Min:", layout=widgets.Layout(width='100px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['enhanced_gaussian_policy']['log_std_bounds'][0],
                    min=-5.0, max=0.0, step=0.1,
                    description="",
                    layout=widgets.Layout(width='150px')
                ),
                widgets.Label("Max:", layout=widgets.Layout(width='40px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['enhanced_gaussian_policy']['log_std_bounds'][1],
                    min=0.0, max=3.0, step=0.1,
                    description="",
                    layout=widgets.Layout(width='150px')
                )
            ]),
            widgets.HBox([
                widgets.Label("Entropy Weight:", layout=widgets.Layout(width='100px')),
                widgets.FloatSlider(
                    value=self.default_action_variation['enhanced_gaussian_policy']['entropy_weight'],
                    min=0.0, max=1.0, step=0.05,
                    description="",
                    layout=widgets.Layout(width='200px')
                ),
                widgets.Label("(Exploration bonus)", layout=widgets.Layout(width='150px'))
            ])
        ])
        
        # Expected results section
        variation_content.extend([
            widgets.HTML("<h4>üìä Expected Results</h4>"),
            widgets.HTML("""
            <div style='background-color: #f0f8ff; padding: 10px; border-radius: 5px;'>
                <b>Current System:</b> Action variation ~0.01 (tiny changes)<br/>
                <b>Enhanced System:</b> Action variation 0.2-0.4 (wide exploration)<br/>
                <br/>
                <b>Physical Impact:</b><br/>
                ‚Ä¢ BHP ranges: 1200-3000 psi (vs 1087-1305 psi narrow)<br/>
                ‚Ä¢ Gas injection: 50K-5M ft¬≥/day (vs 10-25M narrow)<br/>
                ‚Ä¢ Well differentiation: Each well explores differently<br/>
                ‚Ä¢ Temporal correlation: Actions vary smoothly within episodes
            </div>
            """)
        ])
        
        self.action_variation_tab.children = variation_content
    
    def _apply_configuration(self, button):
        """Apply configuration and pre-load ROM model + generate Z0"""
        with self.results_output:
            clear_output(wait=True)
            
            print("üîÑ Applying RL configuration...")
            
            # Collect configuration
            config = self._collect_configuration()
            
            if config:
                self.config.update(config)
                print("‚úÖ Configuration applied successfully!")
                print("Configuration Summary:")
                self._print_configuration_summary()
                
                # Store in a way that can be accessed from training script
                self._store_config_for_training()
                
                # NEW: Load ROM model and generate Z0 immediately
                print("\nüöÄ Pre-loading ROM model and generating Z0...")
                success = self._load_rom_and_generate_z0()
                
                if success:
                    print("üéâ ALL READY! Your models and Z0 are pre-loaded for RL training!")
                    print("   ‚úÖ ROM model: Loaded and ready")
                    print("   ‚úÖ Realistic Z0: Generated and ready")
                    print("   üöÄ Main run file can now start RL training directly!")
                else:
                    print("‚ö†Ô∏è Configuration saved, but model loading failed.")
                    print("   Main run file will handle model loading as fallback.")
                
            else:
                print("‚ùå Configuration failed!")
    
    def _load_rom_and_generate_z0(self):
        """Load ROM model and generate realistic Z0 from selected states"""
        try:
            # Setup device
            import torch
            self.device = torch.device("cuda" if torch.cuda.is_available() 
                                       else ("mps" if torch.backends.mps.is_available() 
                                             else "cpu"))
            print(f"   üîß Using device: {self.device}")
            
            # Check if ROM model is selected
            if not self.config.get('selected_rom'):
                print("‚ùå No ROM model selected!")
                print("   üí° Please:")
                print("      1. Go to the 'üèîÔ∏è States' tab")
                print("      2. Select a ROM model from the dropdown")
                print("      3. Click 'Apply Configuration' again")
                if len(self.config.get('rom_models', [])) == 0:
                    print("   üìÅ No ROM models found. Please:")
                    print("      1. Check the ROM Models Folder path")
                    print("      2. Click 'üîç Scan Folders' to scan for ROM models")
                return False
            
            # Check if states are selected
            if not self.config.get('selected_states'):
                print("‚ùå No states selected!")
                return False
            
            # üéØ CRITICAL: Load ROM config from ROM_Refactored to ensure consistency
            # This ensures ROM model uses EXACT same config as ROM training (no parameter leakage)
            rom_config_path = Path(__file__).parent.parent.parent / 'ROM_Refactored' / 'config.yaml'
            
            if not rom_config_path.exists():
                print(f"‚ùå ROM config not found at {rom_config_path}")
                print("   Please ensure ROM_Refactored/config.yaml exists")
                return False
            
            print(f"   üìÑ Loading ROM config from: {rom_config_path}")
            rom_config = Config(str(rom_config_path))
            
            # üéØ CRITICAL: Extract architecture parameters from selected model filename
            # and update ROM config to match the saved model architecture
            selected_rom = self.config['selected_rom']
            model_info = selected_rom.get('info', {})
            
            print("   üîß Matching ROM config to selected model architecture...")
            config_updated = False
            
            # Update latent_dim if found in model filename
            if 'latent' in model_info or 'latent_dim' in model_info:
                latent_dim = model_info.get('latent_dim') or model_info.get('latent')
                if latent_dim and rom_config.model.get('latent_dim') != latent_dim:
                    rom_config.model['latent_dim'] = latent_dim
                    print(f"      ‚úÖ Updated latent_dim: {rom_config.model.get('latent_dim')} ‚Üí {latent_dim}")
                    config_updated = True
            
            # Update batch_size if found (for reference, though not directly used in model architecture)
            if 'batch_size' in model_info:
                batch_size = model_info['batch_size']
                print(f"      üìä Model was trained with batch_size: {batch_size}")
            
            # Update nsteps if found
            if 'nsteps' in model_info or 'steps' in model_info:
                nsteps = model_info.get('nsteps') or model_info.get('steps')
                if nsteps and rom_config.training.get('nsteps') != nsteps:
                    rom_config.training['nsteps'] = nsteps
                    print(f"      ‚úÖ Updated nsteps: {rom_config.training.get('nsteps')} ‚Üí {nsteps}")
                    config_updated = True
            
            # Update channels if found
            if 'channels' in model_info:
                channels = model_info['channels']
                if channels and rom_config.model.get('n_channels') != channels:
                    rom_config.model['n_channels'] = channels
                    print(f"      ‚úÖ Updated n_channels: {rom_config.model.get('n_channels')} ‚Üí {channels}")
                    config_updated = True
            
            if config_updated:
                print("   ‚úÖ ROM config updated to match selected model architecture")
            else:
                print("   ‚úÖ ROM config matches selected model (no updates needed)")
            
            # Note: ROM config doesn't need RL-specific updates
            # The ROM model will be initialized with ROM config as-is
            # RL-specific parameters are handled separately in RL training
            
            # Initialize ROM model using ROM config (ensures consistency)
            print("   üß† Initializing ROM model with matched architecture...")
            if ROMWithE2C is None:
                print("‚ùå ROMWithE2C not available!")
                return False
            
            self.loaded_rom_model = ROMWithE2C(rom_config).to(self.device)
            
            # Load pre-trained weights
            selected_rom = self.config['selected_rom']
            encoder_file = selected_rom['encoder']
            decoder_file = selected_rom['decoder']
            transition_file = selected_rom['transition']
            
            print("   üì• Loading pre-trained weights...")
            print(f"      ‚Ä¢ Encoder: {os.path.basename(encoder_file)}")
            print(f"      ‚Ä¢ Decoder: {os.path.basename(decoder_file)}")
            print(f"      ‚Ä¢ Transition: {os.path.basename(transition_file)}")
            
            self.loaded_rom_model.model.load_weights_from_file(encoder_file, decoder_file, transition_file)
            self.loaded_rom_model.eval()  # Set to evaluation mode
            print("   ‚úÖ ROM model loaded successfully!")
            
            # Generate realistic Z0 options from ALL cases
            print("   üèîÔ∏è Generating multiple realistic Z0 options from selected states...")
            self.generated_z0_options, selected_states, state_t_seq = generate_z0_from_dashboard(
                self.config, self.loaded_rom_model, self.device
            )
            
            # Store metadata for multiple Z0 options
            self.z0_metadata = {
                'selected_states': selected_states,
                'z0_shape': self.generated_z0_options.shape,
                'z0_device': str(self.generated_z0_options.device),
                'num_cases': self.generated_z0_options.shape[0],
                'z0_stats': {
                    'mean': self.generated_z0_options.mean().item(),
                    'std': self.generated_z0_options.std().item(),
                    'min': self.generated_z0_options.min().item(),
                    'max': self.generated_z0_options.max().item(),
                    'per_case_means': self.generated_z0_options.mean(dim=1),
                    'per_case_stds': self.generated_z0_options.std(dim=1)
                },
                'source': f'Multiple initial states from {self.generated_z0_options.shape[0]} cases'
            }
            
            print(f"   ‚úÖ Multiple Z0 options generated successfully!")
            print(f"      ‚Ä¢ Source states: {selected_states}")
            print(f"      ‚Ä¢ Z0 options shape: {self.generated_z0_options.shape} ({self.generated_z0_options.shape[0]} different initial states)")
            print(f"      ‚Ä¢ Z0 stats: mean={self.z0_metadata['z0_stats']['mean']:.4f}, "
                  f"std={self.z0_metadata['z0_stats']['std']:.4f}")
            print(f"      ‚Ä¢ Ready for random sampling in RL training!")
            
            # Mark as ready
            self.models_ready = True
            
            # Update global storage
            import builtins
            builtins.rl_dashboard_config = self.config
            builtins.rl_loaded_rom = self.loaded_rom_model
            builtins.rl_generated_z0_options = self.generated_z0_options  # Now stores multiple Z0 options
            builtins.rl_z0_metadata = self.z0_metadata
            builtins.rl_models_ready = True
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading ROM and generating Z0: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _collect_configuration(self):
        """Collect configuration from all tabs"""
        config = {}
        
        try:
            # State configuration
            if hasattr(self, 'state_checkboxes'):
                selected_states = []
                state_scaling = {}
                
                for state_name, checkbox in self.state_checkboxes.items():
                    if checkbox.value:
                        selected_states.append(state_name)
                        state_scaling[state_name] = self.scaling_radios[state_name].value
                
                config['selected_states'] = selected_states
                config['state_scaling'] = state_scaling
            
            # ROM model selection
            if hasattr(self, 'rom_selector') and self.rom_selector is not None:
                selected_idx = self.rom_selector.value
                if selected_idx is not None and selected_idx < len(self.config.get('rom_models', [])):
                    config['selected_rom'] = self.config['rom_models'][selected_idx]
                elif len(self.config.get('rom_models', [])) == 0:
                    print("      ‚ö†Ô∏è Warning: No ROM models found. Please scan folders first.")
                else:
                    print("      ‚ö†Ô∏è Warning: No ROM model selected. Please select a ROM model from the dropdown.")
            elif len(self.config.get('rom_models', [])) == 0:
                print("      ‚ö†Ô∏è Warning: No ROM models available. Please scan folders first.")
            else:
                print("      ‚ö†Ô∏è Warning: ROM selector not available. Please scan folders first.")
            
            # Action configuration
            if hasattr(self, 'bhp_ranges'):
                action_ranges = {
                    'bhp': {},
                    'gas_injection': {},
                    'num_wells': self.num_wells_input.value,
                    'num_producers': self.num_prod_input.value
                }
                
                for well, ranges in self.bhp_ranges.items():
                    action_ranges['bhp'][well] = {
                        'min': ranges['min'].value,
                        'max': ranges['max'].value
                    }
                
                for well, ranges in self.gas_ranges.items():
                    action_ranges['gas_injection'][well] = {
                        'min': ranges['min'].value,
                        'max': ranges['max'].value
                    }
                
                config['action_ranges'] = action_ranges
            
            # Economic configuration
            if hasattr(self, 'economic_inputs'):
                economic_params = {}
                for param_key, input_widget in self.economic_inputs.items():
                    if hasattr(input_widget, 'value'):
                        economic_params[param_key] = input_widget.value
                
                # Calculate total capital cost from pre-project parameters
                years_before = economic_params.get('years_before_project_start', 3)
                cost_per_year = economic_params.get('capital_cost_per_year', 6000000.0)
                economic_params['fixed_capital_cost'] = years_before * cost_per_year
                
                config['economic_params'] = economic_params
            
            # RL Hyperparameters configuration
            if hasattr(self, 'rl_hyperparams'):
                rl_hyperparams = {}
                for param_key, input_widget in self.rl_hyperparams.items():
                    rl_hyperparams[param_key] = input_widget.value
                
                config['rl_hyperparams'] = rl_hyperparams
            
            # Action Variation configuration
            if hasattr(self, 'action_variation_tab') and self.action_variation_tab.children:
                action_variation = {}
                
                # Extract values from the action variation tab widgets
                widgets_list = self.action_variation_tab.children
                
                if len(widgets_list) > 1:
                    # Enable/disable checkbox
                    action_variation['enabled'] = widgets_list[1].value if hasattr(widgets_list[1], 'value') else self.default_action_variation['enabled']
                    
                    # Variation mode dropdown  
                    if len(widgets_list) > 3:
                        action_variation['mode'] = widgets_list[3].value if hasattr(widgets_list[3], 'value') else self.default_action_variation['mode']
                    
                    # Use default values for now (could be enhanced to read from widgets)
                    action_variation.update({
                        'noise_decay_rate': self.default_action_variation['noise_decay_rate'],
                        'max_noise_std': self.default_action_variation['max_noise_std'],
                        'min_noise_std': self.default_action_variation['min_noise_std'],
                        'step_variation_amplitude': self.default_action_variation['step_variation_amplitude'],
                        'well_strategies': self.default_action_variation['well_strategies'],
                        'enhanced_gaussian_policy': self.default_action_variation['enhanced_gaussian_policy']
                    })
                
                config['action_variation'] = action_variation
            
            # ROM compatibility handled through training-only normalization parameters
            
            # üéØ CRITICAL: Calculate TRAINING-ONLY normalization parameters (fixes data leakage)
            print("      üîÑ Calculating TRAINING-ONLY normalization parameters...")
            training_params = calculate_training_only_normalization_params(self.state_folder)
            if training_params:
                config['training_only_normalization_params'] = training_params
                print("      ‚úÖ TRAINING-ONLY normalization parameters calculated successfully")
                print(f"         üéØ NO DATA LEAKAGE: Parameters from training split only")
                print(f"         üìä Variables: {list(training_params.keys())}")
                
                # ‚ú® NEW: Automatically save normalization parameters for RL training
                norm_file = save_normalization_parameters_for_rl(training_params)
                if norm_file:
                    print(f"      üîó RL training can now use: {norm_file}")
                    config['normalization_file'] = norm_file
                
                # Compare with JSON parameters to show improvement
                preprocessing_params = self._load_preprocessing_normalization_parameters()
                if preprocessing_params:
                    config['preprocessing_normalization_params'] = preprocessing_params
                    print("      üìä Legacy preprocessing parameters also loaded for comparison")
                    
                    # Compare BHP ranges as example
                    try:
                        json_bhp_min = float(preprocessing_params['control_variables']['BHP']['parameters']['min'])
                        json_bhp_max = float(preprocessing_params['control_variables']['BHP']['parameters']['max'])
                        train_bhp_min = training_params['BHP']['min']
                        train_bhp_max = training_params['BHP']['max']
                        
                        print(f"      üîç BHP Range Comparison:")
                        print(f"         Legacy JSON: [{json_bhp_min:.2f}, {json_bhp_max:.2f}] (data leakage)")
                        print(f"         Training-only: [{train_bhp_min:.2f}, {train_bhp_max:.2f}] (corrected)")
                        
                        if abs(json_bhp_min - train_bhp_min) > 0.01 or abs(json_bhp_max - train_bhp_max) > 0.01:
                            print(f"      ‚ö†Ô∏è CONFIRMED: JSON parameters include test data (DATA LEAKAGE)")
                            print(f"      ‚úÖ Using corrected TRAINING-ONLY parameters")
                        else:
                            print(f"      ‚úÖ JSON parameters appear to be training-only")
                    except:
                        print(f"      üìä Legacy comparison not available")
                else:
                    print("      üí° No legacy preprocessing parameters found for comparison")
            else:
                print("      ‚ùå Failed to calculate training-only parameters")
                # Fallback to preprocessing parameters if available
                preprocessing_params = self._load_preprocessing_normalization_parameters()
                if preprocessing_params:
                    config['preprocessing_normalization_params'] = preprocessing_params
                    print("      ‚ö†Ô∏è Fallback: Using legacy preprocessing parameters (may contain data leakage)")
                else:
                    print("      üö® No normalization parameters available!")
                    print("      üí° Please ensure data files are available in state folder")
            
            # Add folder paths for state processing
            config['state_folder'] = self.state_folder
            config['rom_folder'] = self.rom_folder
            
            return config
            
        except Exception as e:
            print(f"‚ùå Error collecting configuration: {e}")
            return None
    
    def _store_config_for_training(self):
        """Store configuration for use in training script"""
        # Store as global variable that can be accessed
        import builtins
        builtins.rl_dashboard_config = self.config
        print("üíæ Configuration stored globally as 'rl_dashboard_config'")
    
    def _print_configuration_summary(self):
        """Print a summary of the current configuration"""
        print(f"Configuration: {len(self.config.get('selected_states', []))} states selected")
        
        if 'selected_rom' in self.config and self.config['selected_rom'] is not None:
            rom = self.config['selected_rom']
            print(f"ROM: {rom.get('name', 'Unknown')}")
        else:
            print("ROM: Not selected")
        
        if 'action_ranges' in self.config and self.config['action_ranges']:
            ar = self.config['action_ranges']
            num_prod = ar.get('num_producers', 'unknown')
            num_wells = ar.get('num_wells', 6)
            num_inj = num_wells - num_prod if isinstance(num_prod, int) and isinstance(num_wells, int) else 'unknown'
            print(f"Wells: {num_prod} producers, {num_inj} injectors")
        else:
            print("Wells: Not configured")
        
        if 'rl_hyperparams' in self.config and self.config['rl_hyperparams']:
            hp = self.config['rl_hyperparams']
            print(f"\nüß† RL Hyperparameters:")
            print(f"   ‚Ä¢ Policy Type: {hp.get('policy_type', 'unknown')}")
            print(f"   ‚Ä¢ Hidden Dim: {hp.get('hidden_dim', 'unknown')}")
            discount_factor = hp.get('discount_factor', 'unknown')
            if isinstance(discount_factor, (int, float)):
                print(f"   ‚Ä¢ Discount Factor: {discount_factor:.3f}")
            else:
                print(f"   ‚Ä¢ Discount Factor: {discount_factor}")
            critic_lr = hp.get('critic_lr', 'unknown')
            policy_lr = hp.get('policy_lr', 'unknown')
            if isinstance(critic_lr, (int, float)) and isinstance(policy_lr, (int, float)):
                print(f"   ‚Ä¢ Learning Rates: C={critic_lr:.1e}, P={policy_lr:.1e}")
            else:
                print(f"   ‚Ä¢ Learning Rates: C={critic_lr}, P={policy_lr}")
            max_episodes = hp.get('max_episodes', 'unknown')
            max_steps = hp.get('max_steps_per_episode', 'unknown')
            print(f"   ‚Ä¢ Training: {max_episodes} episodes, {max_steps} steps/episode")
            batch_size = hp.get('batch_size', 'unknown')
            replay_capacity = hp.get('replay_capacity', 'unknown')
            print(f"   ‚Ä¢ Batch Size: {batch_size}, Replay: {replay_capacity}")
        else:
            print("\nüß† RL Hyperparameters: Not configured")
    
    def _reset_defaults(self, button):
        """Reset all settings to defaults"""
        with self.results_output:
            clear_output(wait=True)
            print("üîÑ Resetting to default values...")
            
            # Reset folder paths from config (or ROM_Refactored defaults)
            if self.config_obj and hasattr(self.config_obj, 'paths'):
                paths = self.config_obj.paths
                if isinstance(paths, dict):
                    self.rom_folder_input.value = paths.get('rom_models_dir', '../ROM_Refactored/saved_models/')
                    self.state_folder_input.value = paths.get('state_data_dir', '../ROM_Refactored/sr3_batch_output/')
                else:
                    self.rom_folder_input.value = getattr(paths, 'rom_models_dir', '../ROM_Refactored/saved_models/')
                    self.state_folder_input.value = getattr(paths, 'state_data_dir', '../ROM_Refactored/sr3_batch_output/')
            else:
                # Fallback to ROM_Refactored defaults
                self.rom_folder_input.value = "../ROM_Refactored/saved_models/"
                self.state_folder_input.value = "../ROM_Refactored/sr3_batch_output/"
            
            print("‚úÖ Reset completed! Please scan folders again.")
    
    def _save_configuration(self, button):
        """Save current configuration to file"""
        with self.results_output:
            clear_output(wait=True)
            
            config = self._collect_configuration()
            if config:
                # Save to JSON file
                config_file = "rl_config.json"
                
                # Convert numpy types to native Python types for JSON serialization
                json_config = self._convert_for_json(config)
                
                try:
                    with open(config_file, 'w') as f:
                        json.dump(json_config, f, indent=4)
                    print(f"üíæ Configuration saved to {config_file}")
                except Exception as e:
                    print(f"‚ùå Error saving configuration: {e}")
            else:
                print("‚ùå No configuration to save!")
    
    def _convert_for_json(self, obj):
        """Convert numpy types to JSON-serializable types"""
        if isinstance(obj, dict):
            return {key: self._convert_for_json(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_for_json(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        else:
            return obj
    
    def display(self):
        """Display the dashboard"""
        if WIDGETS_AVAILABLE:
            display(self.main_widget)
        else:
            print("‚ùå Cannot display dashboard - ipywidgets not available")
    
    def get_configuration(self):
        """Get the current configuration"""
        return self.config.copy()


def create_rl_configuration_dashboard(config_path='config.yaml'):
    """
    Create and return an RL configuration dashboard
    
    Args:
        config_path: Path to config.yaml file (default: 'config.yaml')
    
    Returns:
        RLConfigurationDashboard: Interactive dashboard instance
    """
    if not WIDGETS_AVAILABLE:
        print("‚ùå Cannot create dashboard - ipywidgets not available")
        print("Please install ipywidgets: pip install ipywidgets")
        return None
    
    print("üéÆ Creating RL Configuration Dashboard...")
    
    dashboard = RLConfigurationDashboard(config_path=config_path)
    
    return dashboard


def launch_rl_config_dashboard(config_path='config.yaml'):
    """
    Launch the RL configuration dashboard
    
    Args:
        config_path: Path to config.yaml file (default: 'config.yaml')
    
    Returns:
        RLConfigurationDashboard: Dashboard instance for configuration
    """
    dashboard = create_rl_configuration_dashboard(config_path=config_path)
    
    if dashboard:
        print("‚úÖ Dashboard created successfully!")
        print("üîß Please configure your RL parameters using the dashboard below.")
        print(f"üìÅ Default paths: ROM Models = {dashboard.rom_folder}, State Data = {dashboard.state_folder}")
        print("   üí° You can change these paths in the 'Folder Configuration' section")
        print("Click 'Apply Configuration' when ready to proceed.")
        dashboard.display()
        return dashboard
    else:
        print("‚ùå Failed to create dashboard")
        return None


# Utility functions for accessing configuration in training script
def get_rl_config():
    """Get the stored RL configuration"""
    import builtins
    if hasattr(builtins, 'rl_dashboard_config'):
        return builtins.rl_dashboard_config
    else:
        print("‚ùå No RL configuration found. Please run the dashboard first.")
        return None


def has_rl_config():
    """Check if RL configuration is available"""
    import builtins
    return hasattr(builtins, 'rl_dashboard_config')


def get_pre_loaded_rom():
    """Get the pre-loaded ROM model from dashboard"""
    import builtins
    if hasattr(builtins, 'rl_loaded_rom'):
        return builtins.rl_loaded_rom
    else:
        print("‚ùå No pre-loaded ROM model found. Please apply dashboard configuration first.")
        return None


def get_pre_generated_z0():
    """Get the pre-generated Z0 options from dashboard for random sampling"""
    import builtins
    if hasattr(builtins, 'rl_generated_z0_options'):
        return builtins.rl_generated_z0_options, builtins.rl_z0_metadata
    else:
        print("‚ùå No pre-generated Z0 options found. Please apply dashboard configuration first.")
        return None, None


def are_models_ready():
    """Check if ROM model and Z0 are pre-loaded and ready"""
    import builtins
    return hasattr(builtins, 'rl_models_ready') and builtins.rl_models_ready


def apply_state_scaling(data, state_name, rl_config):
    """
    Apply scaling to state data based on dashboard configuration
    
    Args:
        data: numpy array of state data
        state_name: name of the state (e.g., 'SW', 'PRES', etc.)
        rl_config: configuration from dashboard
        
    Returns:
        tuple: (scaled_data, scaling_params)
    """
    if state_name not in rl_config.get('state_scaling', {}):
        print(f"‚ö†Ô∏è No scaling configuration for {state_name}, using min-max")
        scaling_type = 'minmax'
    else:
        scaling_type = rl_config['state_scaling'][state_name]
    
    if scaling_type == 'log':
        # Log normalization
        epsilon = 1e-8
        positive_data = data[data > 0]
        if len(positive_data) > 0:
            min_pos = np.min(positive_data)
            data_shifted = np.maximum(data, min_pos)  # Ensure all values >= min_pos
        else:
            data_shifted = data + epsilon
        
        log_data = np.log(data_shifted + epsilon)
        log_min = np.min(log_data)
        log_max = np.max(log_data)
        
        if log_max > log_min:
            scaled_data = (log_data - log_min) / (log_max - log_min)
        else:
            scaled_data = np.zeros_like(log_data)
            
        scaling_params = {
            'type': 'log',
            'log_min': log_min,
            'log_max': log_max,
            'epsilon': epsilon,
            'min_positive': min_pos if len(positive_data) > 0 else epsilon
        }
        
    else:
        # Min-max normalization (default)
        positive_data = data[data > 0]
        if len(positive_data) > 0:
            data_min = np.min(positive_data)  # Use minimum positive value
        else:
            data_min = np.min(data)
            
        data_max = np.max(data)
        
        if data_max > data_min:
            scaled_data = (data - data_min) / (data_max - data_min)
        else:
            scaled_data = np.zeros_like(data)
            
        scaling_params = {
            'type': 'minmax',
            'min': data_min,
            'max': data_max
        }
    
    return scaled_data, scaling_params


def get_action_scaling_params(rl_config):
    """
    Get action scaling parameters from dashboard configuration
    
    Args:
        rl_config: configuration from dashboard
        
    Returns:
        dict: scaling parameters for actions
    """
    action_ranges = rl_config.get('action_ranges', {})
    
    scaling_params = {
        'bhp': {},
        'gas_injection': {},
        'num_producers': action_ranges.get('num_producers', 3),
        'num_injectors': action_ranges.get('num_wells', 6) - action_ranges.get('num_producers', 3)
    }
    
    # BHP scaling parameters
    bhp_ranges = action_ranges.get('bhp', {})
    if bhp_ranges:
        # Aggregate min and max across all wells
        bhp_mins = [ranges['min'] for ranges in bhp_ranges.values()]
        bhp_maxs = [ranges['max'] for ranges in bhp_ranges.values()]
        
        scaling_params['bhp'] = {
            'min': min(bhp_mins) if bhp_mins else 1087.78,
            'max': max(bhp_maxs) if bhp_maxs else 1305.0,
            'ranges': bhp_ranges
        }
    else:
        # Default values
        scaling_params['bhp'] = {
            'min': 1087.78,
            'max': 1305.0,
            'ranges': {}
        }
    
    # Gas injection scaling parameters
    gas_ranges = action_ranges.get('gas_injection', {})
    if gas_ranges:
        # Aggregate min and max across all wells
        gas_mins = [ranges['min'] for ranges in gas_ranges.values()]
        gas_maxs = [ranges['max'] for ranges in gas_ranges.values()]
        
        scaling_params['gas_injection'] = {
            'min': min(gas_mins) if gas_mins else 10064800.2,
            'max': max(gas_maxs) if gas_maxs else 24720266.0,
            'ranges': gas_ranges
        }
    else:
        # Default values
        scaling_params['gas_injection'] = {
            'min': 10064800.2,
            'max': 24720266.0,
            'ranges': {}
        }
    
    return scaling_params


def get_reward_function_params(rl_config):
    """
    Get reward function parameters from dashboard configuration
    
    Args:
        rl_config: configuration from dashboard
        
    Returns:
        dict: parameters for reward function
    """
    economic_params = rl_config.get('economic_params', {})
    
    # Default values from the current implementation
    defaults = {
        'gas_injection_revenue': 50.0,  # Gas injection credit per ton ($/ton)
        'gas_injection_cost': 10.0,     # Gas injection cost per ton ($/ton)
        'water_production_penalty': 5.0,    # from reward function
        'gas_production_penalty': 50.0, # from reward function
        'lf3_to_ton_conversion': 0.1167 * 4.536e-4,
        'scale_factor': 1000000.0  # Updated to 1 million for proper RL reward scaling
    }
    
    # Merge with user configuration
    reward_params = {**defaults, **economic_params}
    
    return reward_params


def update_config_with_dashboard(config, rl_config):
    """
    Update the main config object with values from dashboard configuration
    
    Args:
        config: Main Config object from config.yaml (must have rl_model section for RL config)
        rl_config: Dashboard configuration
        
    Returns:
        None: Modifies config in place
    """
    if not rl_config:
        return
    
    # Check if config has rl_model section (RL config) or not (ROM config)
    try:
        # Try to access rl_model to check if it exists
        _ = config.rl_model
        has_rl_model = True
    except (AttributeError, KeyError):
        # ROM config doesn't have rl_model section - skip RL-specific updates
        return
    
    # Update reservoir configuration (only for RL config)
    action_ranges = rl_config.get('action_ranges', {})
    if action_ranges:
        config.rl_model['reservoir']['num_producers'] = action_ranges.get('num_producers', 3)
        config.rl_model['reservoir']['num_injectors'] = action_ranges.get('num_wells', 6) - action_ranges.get('num_producers', 3)
    
    # Store action ranges in ROM training normalization section (for compatibility)
    if 'bhp' in action_ranges:
        bhp_ranges = action_ranges['bhp']
        if bhp_ranges:
            bhp_mins = [ranges['min'] for ranges in bhp_ranges.values()]
            bhp_maxs = [ranges['max'] for ranges in bhp_ranges.values()]
            # Store in ROM training section instead of action_constraints
            if 'rom_training_normalization' not in config.rl_model:
                config.rl_model['rom_training_normalization'] = {}
            config.rl_model['rom_training_normalization']['bhp_params'] = {
                'min': min(bhp_mins),
                'max': max(bhp_maxs)
            }
    
    if 'gas_injection' in action_ranges:
        gas_ranges = action_ranges['gas_injection']
        if gas_ranges:
            gas_mins = [ranges['min'] for ranges in gas_ranges.values()]
            gas_maxs = [ranges['max'] for ranges in gas_ranges.values()]
            # Store in ROM training section instead of action_constraints
            if 'rom_training_normalization' not in config.rl_model:
                config.rl_model['rom_training_normalization'] = {}
            config.rl_model['rom_training_normalization']['gas_injection_params'] = {
                'min': min(gas_mins),
                'max': max(gas_maxs)
            }
    
    # Update economic parameters
    economic_params = rl_config.get('economic_params', {})
    if economic_params:
        if 'gas_injection_revenue' in economic_params:
            config.rl_model['economics']['prices']['gas_injection_revenue'] = economic_params['gas_injection_revenue']
        
        if 'gas_injection_cost' in economic_params:
            config.rl_model['economics']['prices']['gas_injection_cost'] = economic_params['gas_injection_cost']
        
        if 'water_production_penalty' in economic_params:
            config.rl_model['economics']['prices']['water_production_penalty'] = economic_params['water_production_penalty']
        
        if 'gas_production_penalty' in economic_params:
            config.rl_model['economics']['prices']['gas_production_penalty'] = economic_params['gas_production_penalty']
        
        if 'lf3_to_ton_conversion' in economic_params:
            # Split conversion factor back into components
            total_conversion = economic_params['lf3_to_ton_conversion']
            config.rl_model['economics']['conversion']['lf3_to_intermediate'] = 0.1167
            config.rl_model['economics']['conversion']['intermediate_to_ton'] = total_conversion / 0.1167
        
        if 'scale_factor' in economic_params:
            config.rl_model['economics']['scale_factor'] = economic_params['scale_factor']
    
    # Update RL hyperparameters
    rl_hyperparams = rl_config.get('rl_hyperparams', {})
    if rl_hyperparams:
        # Network parameters
        if 'hidden_dim' in rl_hyperparams:
            config.rl_model['networks']['hidden_dim'] = rl_hyperparams['hidden_dim']
        
        if 'policy_type' in rl_hyperparams:
            config.rl_model['networks']['policy']['type'] = rl_hyperparams['policy_type']
        
        if 'output_activation' in rl_hyperparams:
            config.rl_model['networks']['policy']['output_activation'] = rl_hyperparams['output_activation']
        
        # SAC parameters
        if 'discount_factor' in rl_hyperparams:
            config.rl_model['sac']['discount_factor'] = rl_hyperparams['discount_factor']
        
        if 'soft_update_tau' in rl_hyperparams:
            config.rl_model['sac']['soft_update_tau'] = rl_hyperparams['soft_update_tau']
        
        if 'entropy_alpha' in rl_hyperparams:
            config.rl_model['sac']['entropy']['alpha'] = rl_hyperparams['entropy_alpha']
        
        if 'critic_lr' in rl_hyperparams:
            config.rl_model['sac']['learning_rates']['critic'] = rl_hyperparams['critic_lr']
        
        if 'policy_lr' in rl_hyperparams:
            config.rl_model['sac']['learning_rates']['policy'] = rl_hyperparams['policy_lr']
        
        if 'gradient_clipping' in rl_hyperparams:
            config.rl_model['sac']['gradient_clipping']['enable'] = rl_hyperparams['gradient_clipping']
        
        if 'max_norm' in rl_hyperparams:
            config.rl_model['sac']['gradient_clipping']['policy_max_norm'] = rl_hyperparams['max_norm']
        
        # Training parameters
        if 'max_episodes' in rl_hyperparams:
            config.rl_model['training']['max_episodes'] = rl_hyperparams['max_episodes']
        
        if 'max_steps_per_episode' in rl_hyperparams:
            config.rl_model['training']['max_steps_per_episode'] = rl_hyperparams['max_steps_per_episode']
            config.rl_model['environment']['max_episode_steps'] = rl_hyperparams['max_steps_per_episode']
        
        # Environment prediction mode
        if 'prediction_mode' in rl_hyperparams:
            config.rl_model['environment']['prediction_mode'] = rl_hyperparams['prediction_mode']
        
        if 'batch_size' in rl_hyperparams:
            config.rl_model['replay_memory']['batch_size'] = rl_hyperparams['batch_size']
        
        if 'replay_capacity' in rl_hyperparams:
            config.rl_model['replay_memory']['capacity'] = rl_hyperparams['replay_capacity']
    
    print("‚úÖ Config updated with dashboard values!")


def create_rl_reward_function(rl_config):
    """
    Create a reward function based on dashboard configuration
    
    Args:
        rl_config: configuration from dashboard
        
    Returns:
        function: configured reward function
    """
    reward_params = get_reward_function_params(rl_config)
    
    def reward_function(yobs, action, num_prod, num_inj):
        """
        Configured reward function based on dashboard parameters
        üéØ USES OPTIMAL STRUCTURE FROM DASHBOARD
        
        Args:
            yobs: observations [Injector_BHP(0-2), Gas_Production(3-5), Water_Production(6-8)]
            action: actions [Producer_BHP(0-2), Gas_Injection(3-5)]  
            num_prod: number of producers
            num_inj: number of injectors
            
        Returns:
            torch.Tensor: reward value
        """
        # Extract parameters
        gas_revenue = reward_params['gas_injection_revenue']
        gas_cost = reward_params['gas_injection_cost']
        water_penalty = reward_params['water_production_penalty']
        gas_penalty = reward_params['gas_production_penalty']
        conversion = reward_params['lf3_to_ton_conversion']
        scale = reward_params['scale_factor']
        
        # Calculate PV using configured parameters
        # Formula: (gas_injection_revenue - gas_injection_cost) * conversion - water_penalty - gas_penalty
        injection_revenue = gas_revenue * conversion * torch.sum(action[:, num_prod:], dim=1)
        injection_cost = gas_cost * conversion * torch.sum(action[:, num_prod:], dim=1)
        water_production_penalty = water_penalty * torch.sum(yobs[:, :num_prod], dim=1)
        gas_production_penalty = gas_penalty * conversion * torch.sum(yobs[:, num_prod:num_prod*2], dim=1)
        
        PV = (injection_revenue - injection_cost - water_production_penalty - gas_production_penalty) / scale
        
        return PV
    
    return reward_function


def print_dashboard_summary():
    """Print a summary of the dashboard configuration"""
    config = get_rl_config()
    if not config:
        print("‚ùå No configuration found")
        return
    
    # States
    selected_states = config.get('selected_states', [])
    print(f"Configuration: {len(selected_states)} states selected")
    
    # ROM
    if 'selected_rom' in config and config['selected_rom']:
        rom = config['selected_rom']
        print(f"ROM: {rom['name']}")
    
    # Actions
    action_params = get_action_scaling_params(config)
    print(f"Wells: {action_params['num_producers']} producers, {action_params['num_injectors']} injectors")

